---
phase: 03-ai-personalization
plan: 07
type: execute
wave: 3
depends_on: ["03-03", "03-06"]
files_modified:
  - apps/slack-backend/src/services/ai.ts
  - apps/slack-backend/src/workers/ai-processor.ts
autonomous: true

must_haves:
  truths:
    - "AI suggestions incorporate user's style context"
    - "AI refinements track feedback for future learning"
    - "Prompt caching reduces cost for repeated style context"
    - "Personalization gracefully degrades for new users"
  artifacts:
    - path: "apps/slack-backend/src/services/ai.ts"
      provides: "Enhanced AI service with personalization"
      exports: ["generateSuggestion", "refineSuggestion"]
  key_links:
    - from: "apps/slack-backend/src/services/ai.ts"
      to: "apps/slack-backend/src/services/personalization/styleContextBuilder.ts"
      via: "buildStyleContext import"
      pattern: "import.*buildStyleContext.*from"
    - from: "apps/slack-backend/src/services/ai.ts"
      to: "apps/slack-backend/src/services/personalization/feedbackTracker.ts"
      via: "trackRefinement for feedback loop"
      pattern: "trackRefinement"
---

<objective>
Enhance the existing AI service to integrate style context from the personalization system and implement prompt caching for cost optimization.

Purpose: This plan completes AI-04 (apply style guidance) and AI-08 (improve from feedback). The existing generateSuggestion and refineSuggestion functions are extended to use the three-source style context. Prompt caching is added to reduce costs when the same user makes multiple requests.

Output: Updated ai.ts that generates personalized suggestions matching user's communication style, with automatic feedback tracking on refinements.

Dependencies:
- 03-03: Provides `trackRefinement` function for feedback loop (direct import)
- 03-06: Provides `buildStyleContext` function for style context assembly (direct import)
  - Note: 03-06 transitively depends on 03-02, 03-03, 03-05 for the full personalization stack
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-personalization/03-RESEARCH.md
@apps/slack-backend/src/services/ai.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update AI service with style context integration</name>
  <files>apps/slack-backend/src/services/ai.ts</files>
  <action>
Update ai.ts to integrate the style context builder. Key changes:

1. Add imports for personalization services
2. Update SuggestionContext to include workspaceId and userId
3. Update generateSuggestion to:
   - Build style context using buildStyleContext()
   - Include style context in system prompt with prompt caching
   - Log personalization metadata
4. Update refineSuggestion to:
   - Track refinement events via trackRefinement()
   - Include style context for consistency
5. Add prompt caching headers to Claude API calls

```typescript
import Anthropic from '@anthropic-ai/sdk';
import { env } from '../env.js';
import { prepareForAI, sanitizeAIOutput } from '@slack-speak/validation';
import { logger } from '../utils/logger.js';
import { buildStyleContext, trackRefinement } from './personalization/index.js';

const anthropic = new Anthropic({
  apiKey: env.ANTHROPIC_API_KEY,
});

interface SuggestionContext {
  workspaceId: string;
  userId: string;
  triggerMessage: string;
  contextMessages: Array<{
    userId: string;
    text: string;
    ts: string;
  }>;
  triggeredBy: 'mention' | 'reply' | 'thread' | 'message_action';
}

interface SuggestionResult {
  suggestion: string;
  processingTimeMs: number;
  personalization: {
    learningPhase: string;
    usedHistory: boolean;
  };
}

interface RefinementHistoryEntry {
  suggestion: string;
  refinementRequest?: string;
}

interface RefinementContext {
  workspaceId: string;
  userId: string;
  suggestionId: string;
  originalSuggestion: string;
  refinementRequest: string;
  history?: RefinementHistoryEntry[];
}

// Base system prompt (static, cached for 1 hour)
const BASE_SYSTEM_PROMPT = `You are a helpful assistant that suggests professional, thoughtful responses to workplace messages.

Your suggestions should:
- Be appropriate for professional communication
- Be concise but complete
- Address the key points in the message
- Not be aggressive or confrontational

When suggesting responses, consider the conversation context provided. Generate a single suggested response that the user can copy and send.`;

export async function generateSuggestion(
  context: SuggestionContext
): Promise<SuggestionResult> {
  const startTime = Date.now();

  // Build personalized style context
  const formattedContext = context.contextMessages
    .map(m => `[${m.ts}] User ${m.userId}: ${m.text}`)
    .join('\n');

  const styleContext = await buildStyleContext({
    workspaceId: context.workspaceId,
    userId: context.userId,
    conversationContext: formattedContext,
  });

  // Prepare user content with sanitization and spotlighting
  const sanitizedTrigger = prepareForAI(context.triggerMessage).sanitized;
  const sanitizedContext = prepareForAI(formattedContext).sanitized;

  const userPrompt = `Here is the recent conversation context:
${sanitizedContext}

The user needs help responding to this message:
${sanitizedTrigger}

Trigger type: ${context.triggeredBy}

Please suggest a professional response the user could send. Provide only the suggested response text, no additional commentary.`;

  try {
    const response = await anthropic.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 1024,
      system: [
        {
          type: 'text',
          text: BASE_SYSTEM_PROMPT,
          // Cache static system prompt for 1 hour
          cache_control: { type: 'ephemeral' },
        },
        {
          type: 'text',
          text: styleContext.promptText,
          // Cache user style context for 5 minutes
          cache_control: { type: 'ephemeral' },
        },
      ],
      messages: [
        {
          role: 'user',
          content: userPrompt,
        },
      ],
    });

    const rawSuggestion = response.content[0].type === 'text'
      ? response.content[0].text
      : '';

    // Sanitize AI output before returning
    const suggestion = sanitizeAIOutput(rawSuggestion);

    const processingTimeMs = Date.now() - startTime;

    logger.info({
      processingTimeMs,
      inputTokens: response.usage.input_tokens,
      outputTokens: response.usage.output_tokens,
      cacheReadTokens: (response.usage as any).cache_read_input_tokens || 0,
      cacheCreationTokens: (response.usage as any).cache_creation_input_tokens || 0,
      learningPhase: styleContext.learningPhase,
      usedHistory: styleContext.usedHistory,
    }, 'AI suggestion generated with personalization');

    return {
      suggestion,
      processingTimeMs,
      personalization: {
        learningPhase: styleContext.learningPhase,
        usedHistory: styleContext.usedHistory,
      },
    };
  } catch (error) {
    logger.error({ error }, 'Failed to generate AI suggestion');
    throw error;
  }
}

/**
 * Refine an existing suggestion based on user feedback
 * Supports multi-turn refinement with history tracking
 * Automatically tracks refinement for feedback learning
 */
export async function refineSuggestion(
  context: RefinementContext
): Promise<SuggestionResult> {
  const startTime = Date.now();

  // Build style context for consistency
  const styleContext = await buildStyleContext({
    workspaceId: context.workspaceId,
    userId: context.userId,
    conversationContext: context.originalSuggestion,
  });

  // Build refinement history for context
  const historyText = context.history && context.history.length > 0
    ? context.history.map((entry, idx) => {
        const parts = [`Round ${idx + 1} suggestion: ${entry.suggestion}`];
        if (entry.refinementRequest) {
          parts.push(`User requested: ${entry.refinementRequest}`);
        }
        return parts.join('\n');
      }).join('\n\n')
    : '';

  const roundNumber = (context.history?.length || 0) + 1;

  // Prepare user content with sanitization and spotlighting
  const sanitizedOriginal = prepareForAI(context.originalSuggestion).sanitized;
  const sanitizedRequest = prepareForAI(context.refinementRequest).sanitized;
  const sanitizedHistory = historyText ? prepareForAI(historyText).sanitized : '';

  const refinementSystemPrompt = `You are a helpful assistant that refines professional response suggestions based on user feedback.

Your refined suggestions should:
- Address the specific refinement request from the user
- Maintain professional tone and appropriateness
- Keep the core message intact unless the user asks to change it
- Be concise but complete

When refining, consider what the user is asking for (e.g., "make it shorter", "more formal", "friendlier", "add a question") and adjust accordingly.`;

  const userPrompt = `${sanitizedHistory ? `Previous refinement rounds:\n${sanitizedHistory}\n\n` : ''}Original suggestion:
${sanitizedOriginal}

The user wants to refine this suggestion with the following request:
${sanitizedRequest}

Please provide the refined response text. Provide only the suggested response text, no additional commentary.`;

  try {
    const response = await anthropic.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 1024,
      system: [
        {
          type: 'text',
          text: refinementSystemPrompt,
          cache_control: { type: 'ephemeral' },
        },
        {
          type: 'text',
          text: styleContext.promptText,
          cache_control: { type: 'ephemeral' },
        },
      ],
      messages: [
        {
          role: 'user',
          content: userPrompt,
        },
      ],
    });

    const rawSuggestion = response.content[0].type === 'text'
      ? response.content[0].text
      : '';

    // Sanitize AI output before returning
    const suggestion = sanitizeAIOutput(rawSuggestion);

    const processingTimeMs = Date.now() - startTime;

    // Track refinement for feedback learning
    try {
      await trackRefinement({
        workspaceId: context.workspaceId,
        userId: context.userId,
        suggestionId: context.suggestionId,
        original: context.originalSuggestion,
        modified: suggestion,
      });
    } catch (trackError) {
      // Non-fatal - don't fail the refinement if tracking fails
      logger.warn({ error: trackError }, 'Failed to track refinement event');
    }

    logger.info({
      processingTimeMs,
      inputTokens: response.usage.input_tokens,
      outputTokens: response.usage.output_tokens,
      cacheReadTokens: (response.usage as any).cache_read_input_tokens || 0,
      roundNumber,
      learningPhase: styleContext.learningPhase,
    }, 'AI refinement generated');

    return {
      suggestion,
      processingTimeMs,
      personalization: {
        learningPhase: styleContext.learningPhase,
        usedHistory: styleContext.usedHistory,
      },
    };
  } catch (error) {
    logger.error({ error, roundNumber }, 'Failed to generate AI refinement');
    throw error;
  }
}
```

Key changes from original:
1. Added workspaceId, userId to SuggestionContext
2. Added personalization metadata to SuggestionResult
3. buildStyleContext() called before API request
4. System prompt split into BASE_SYSTEM_PROMPT + styleContext.promptText with cache_control
5. trackRefinement() called after successful refinement (non-fatal if fails)
6. Logging includes cache token metrics and personalization info
  </action>
  <verify>
Run `npx tsc --noEmit -p apps/slack-backend/tsconfig.json` - should compile without errors.
  </verify>
  <done>
ai.ts generates personalized suggestions using style context and tracks refinement feedback.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update AI processor to provide workspaceId and userId</name>
  <files>apps/slack-backend/src/workers/ai-processor.ts</files>
  <action>
Update the AI processor worker to pass workspaceId and userId to generateSuggestion.

Specific changes required:

1. Read the current ai-processor.ts implementation
2. Locate where generateSuggestion is called
3. Update the SuggestionContext passed to generateSuggestion to include:
   - `workspaceId`: Extract from job data (likely `job.data.workspaceId` or `job.data.teamId`)
   - `userId`: Extract from job data (likely `job.data.userId` or `job.data.event.user`)
4. If the job data structure uses different field names (e.g., `teamId` instead of `workspaceId`), map them appropriately

Expected pattern:
```typescript
// Before (missing workspaceId/userId):
const result = await generateSuggestion({
  triggerMessage: job.data.triggerMessage,
  contextMessages: job.data.contextMessages,
  triggeredBy: job.data.triggeredBy,
});

// After (with workspaceId/userId):
const result = await generateSuggestion({
  workspaceId: job.data.workspaceId || job.data.teamId,
  userId: job.data.userId,
  triggerMessage: job.data.triggerMessage,
  contextMessages: job.data.contextMessages,
  triggeredBy: job.data.triggeredBy,
});
```

If the job enqueueing code (in event handlers) doesn't include workspaceId/userId in the job data, also update those call sites to pass the required fields. The workspaceId and userId should be available from the Slack event context.
  </action>
  <verify>
Run `npx tsc --noEmit -p apps/slack-backend/tsconfig.json` - verify ai-processor.ts compiles without type errors for the SuggestionContext interface.
  </verify>
  <done>
AI processor passes workspaceId and userId to generateSuggestion, enabling personalization.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit -p apps/slack-backend/tsconfig.json` passes
2. generateSuggestion calls buildStyleContext before API request
3. refineSuggestion calls trackRefinement after successful response
4. Prompt caching headers present in Claude API calls
5. SuggestionResult includes personalization metadata
6. ai-processor.ts passes required context to AI service
</verification>

<success_criteria>
- Style context included in all AI suggestions (AI-04)
- Refinement feedback tracked automatically (AI-07, AI-08)
- Prompt caching configured for cost optimization
- Personalization gracefully degrades (learningPhase indicates status)
- Existing tests may need updates for new interface (defer to testing phase)
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-personalization/03-07-SUMMARY.md`
</output>
