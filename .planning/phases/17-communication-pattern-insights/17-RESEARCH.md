# Phase 17: Communication Pattern Insights - Research

**Researched:** 2026-02-04
**Domain:** Topic classification, sentiment trend analysis, communication hotspot detection
**Confidence:** HIGH

## Summary

Phase 17 builds on Phase 16's suggestion_metrics table and Phase 12's sentiment detection service to surface communication patterns and hotspots through topic classification and trend aggregation. The domain combines three established patterns: Claude-based text classification (already proven in Phase 12 sentiment detection), PostgreSQL time-series aggregation with precomputed rollups (TimescaleDB continuous aggregate pattern), and Tremor charts for visualization (already in codebase from Phase 13).

The architecture follows existing patterns: fire-and-forget topic classification after suggestion generation (like sentiment detection), BullMQ scheduled jobs for periodic trend aggregation (like data retention cleanup), and admin dashboard pages with Tremor charts (like Phase 16 response-times dashboard). Key challenges are topic taxonomy design (solved with 7 established customer service categories), aggregation granularity trade-offs (daily rollups strike balance between freshness and storage), and period-over-period comparison queries (solved with PostgreSQL window functions).

The existing codebase provides strong foundations: sentiment detection service with Claude prompting and 3s timeout, suggestion_metrics table with workspace/org/user/channel indexes, escalation_alerts table with risk level tracking, Tremor charts with time-series data, and BullMQ repeatable jobs with cron expressions. Phase 17 extends these patterns to provide communication intelligence that identifies problem areas before they escalate.

**Primary recommendation:** Use Claude prompting for topic classification (256 max_tokens, same pattern as sentiment detection), precomputed communication_trends table with daily aggregates (avoid real-time aggregation overhead), and Tremor charts with period-over-period comparison (line charts for trends, bar charts for topic distribution, heat maps for channel hotspots).

## Standard Stack

The established libraries/tools for communication pattern analytics (2026):

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| Claude AI | Sonnet 4 | Topic classification via prompting | Already in codebase, zero incremental cost, proven in Phase 12 sentiment detection |
| PostgreSQL | 17+ | Time-series aggregation with date_trunc | Already in codebase, excellent window functions, mature |
| Drizzle ORM | 0.38.3+ | Schema and aggregation queries | Already in codebase, raw SQL support for complex aggregations |
| BullMQ | 5.19+ | Scheduled trend aggregation jobs | Already in codebase, repeatable jobs with cron expressions |
| Tremor | Latest | Dashboard charts and visualizations | Already in codebase from Phase 13, beautiful defaults |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| date-fns | 4.1.0+ | Date formatting and period calculations | Already in codebase, period-over-period comparisons |
| papaparse | Latest | CSV export for trend data | Already in codebase from Phase 13, CSV export pattern established |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Claude classification | Pre-trained ML model (scikit-learn, TensorFlow) | More control but requires training data, hosting, and ongoing maintenance |
| Precomputed trends | Real-time aggregation on query | Simpler architecture but kills performance with large datasets |
| BullMQ scheduled jobs | PostgreSQL pg_cron | More efficient but requires extension installation, less portable |
| Daily aggregates | Hourly aggregates | More granular but 24x storage cost, likely overkill for communication patterns |

**Installation:**
No new dependencies required. All libraries already in codebase from previous phases.

## Architecture Patterns

### Recommended Project Structure
```
apps/slack-backend/src/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ topic-classifier.ts          # Claude-based classification (like sentiment-detector.ts)
‚îÇ   ‚îú‚îÄ‚îÄ trend-aggregator.ts          # Aggregation logic for background job
‚îÇ   ‚îî‚îÄ‚îÄ index.ts                     # Export new services
‚îú‚îÄ‚îÄ workers/
‚îÇ   ‚îî‚îÄ‚îÄ trend-aggregator-worker.ts   # BullMQ worker for scheduled aggregation
packages/database/src/
‚îú‚îÄ‚îÄ schema.ts                        # New tables: topic_classifications, communication_trends
apps/web-portal/
‚îú‚îÄ‚îÄ lib/admin/
‚îÇ   ‚îî‚îÄ‚îÄ communication-insights.ts    # Query library for insights dashboard
‚îú‚îÄ‚îÄ app/admin/
‚îÇ   ‚îî‚îÄ‚îÄ communication-insights/
‚îÇ       ‚îî‚îÄ‚îÄ page.tsx                 # Dashboard page with Tremor charts
‚îú‚îÄ‚îÄ components/admin/
‚îÇ   ‚îî‚îÄ‚îÄ communication-insights-charts.tsx  # Chart components
```

### Pattern 1: Fire-and-Forget Topic Classification
**What:** Classify suggestion topic after generation completes, never block suggestion delivery
**When to use:** Same as sentiment detection ‚Äî after AI generates suggestion, before user sees it

**Example:**
```typescript
// Source: Phase 12 sentiment-detector.ts pattern
// apps/slack-backend/src/services/topic-classifier.ts

import Anthropic from '@anthropic-ai/sdk';
import { env } from '../env.js';
import { logger } from '../utils/logger.js';

const anthropic = new Anthropic({ apiKey: env.ANTHROPIC_API_KEY });

export type Topic =
  | 'scheduling'       // Meeting requests, calendar coordination
  | 'complaint'        // Issues, problems, dissatisfaction
  | 'technical'        // Tech support, how-to, troubleshooting
  | 'status_update'    // Project updates, progress reports
  | 'request'          // Feature requests, asks for things
  | 'escalation'       // Needs management, urgent attention
  | 'general';         // Casual conversation, unclear

export interface TopicClassification {
  topic: Topic;
  confidence: number; // 0.0-1.0
  reasoning: string;  // Why this topic was chosen
}

const TOPIC_PROMPT = `Classify the topic of this message conversation. Focus on the PRIMARY topic.

Conversation context:
{context}

Most recent message: "{targetMessage}"

Respond ONLY with valid JSON (no markdown):
{
  "topic": "scheduling|complaint|technical|status_update|request|escalation|general",
  "confidence": 0.0-1.0,
  "reasoning": "brief explanation"
}

Topic definitions:
- scheduling: Meeting requests, calendar coordination, availability discussions
- complaint: Issues, problems, dissatisfaction with service/product
- technical: Tech support, how-to questions, troubleshooting
- status_update: Project progress, status reports, updates
- request: Feature requests, asking for things, needs
- escalation: Urgent issues needing management attention, threats to escalate
- general: Casual conversation, unclear primary topic`;

export async function classifyTopic(params: {
  conversationMessages: Array<{ text: string; ts: string }>;
  targetMessage: string;
}): Promise<TopicClassification> {
  const startTime = Date.now();

  const fallback: TopicClassification = {
    topic: 'general',
    confidence: 0,
    reasoning: 'classification_failed',
  };

  try {
    const context = params.conversationMessages
      .map(m => `[${m.ts}] ${m.text}`)
      .join('\n');

    const prompt = TOPIC_PROMPT
      .replace('{context}', context)
      .replace('{targetMessage}', params.targetMessage);

    // 2-second timeout (faster than sentiment since less complex)
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 2000);

    try {
      const response = await anthropic.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 256,
        messages: [{ role: 'user', content: prompt }],
      }, { signal: controller.signal as any });

      clearTimeout(timeoutId);

      const rawContent = response.content[0].type === 'text'
        ? response.content[0].text
        : '';

      const parsed = JSON.parse(rawContent.trim());

      // Validate
      const validTopics: Topic[] = [
        'scheduling', 'complaint', 'technical', 'status_update',
        'request', 'escalation', 'general'
      ];

      if (!validTopics.includes(parsed.topic)) {
        logger.warn({ parsedTopic: parsed.topic }, 'Invalid topic, using fallback');
        return fallback;
      }

      if (typeof parsed.confidence !== 'number' || parsed.confidence < 0 || parsed.confidence > 1) {
        logger.warn({ parsedConfidence: parsed.confidence }, 'Invalid confidence, using fallback');
        return fallback;
      }

      const result: TopicClassification = {
        topic: parsed.topic,
        confidence: parsed.confidence,
        reasoning: parsed.reasoning || 'no_reasoning',
      };

      logger.info({
        topic: result.topic,
        confidence: result.confidence,
        processingTimeMs: Date.now() - startTime,
      }, 'Topic classification complete');

      return result;
    } catch (abortError) {
      if ((abortError as any).name === 'AbortError') {
        logger.warn({ timeoutMs: 2000 }, 'Topic classification timed out');
        return fallback;
      }
      throw abortError;
    } finally {
      clearTimeout(timeoutId);
    }
  } catch (error) {
    logger.warn({ error, processingTimeMs: Date.now() - startTime }, 'Topic classification failed');
    return fallback;
  }
}
```

### Pattern 2: Precomputed Trend Aggregation with BullMQ
**What:** Daily scheduled job aggregates topic counts, sentiment distribution, escalation rates by org/workspace/channel/user
**When to use:** Reporting data that doesn't need real-time updates, expensive to compute on-the-fly

**Example:**
```typescript
// Source: BullMQ Repeatable Jobs pattern
// https://docs.bullmq.io/guide/jobs/repeatable

import { Queue, Worker } from 'bullmq';
import { db, topicClassifications, suggestionMetrics, escalationAlerts } from '@slack-speak/database';
import { sql, eq, and, gte } from 'drizzle-orm';

// Setup queue
const trendQueue = new Queue('trend-aggregation', {
  connection: redis,
});

// Schedule daily aggregation at 3 AM
await trendQueue.add(
  'aggregate-daily-trends',
  {},
  {
    repeat: {
      pattern: '0 3 * * *', // Cron: daily at 3 AM
    },
  }
);

// Worker processor
const trendWorker = new Worker('trend-aggregation', async (job) => {
  logger.info({ jobId: job.id }, 'Starting trend aggregation');

  const yesterday = new Date();
  yesterday.setDate(yesterday.getDate() - 1);
  yesterday.setHours(0, 0, 0, 0);

  const today = new Date();
  today.setHours(0, 0, 0, 0);

  // Get all organizations
  const orgs = await db.select().from(organizations);

  for (const org of orgs) {
    try {
      // Aggregate topic distribution
      const topicAgg = await db.execute(sql`
        SELECT
          DATE(${topicClassifications.createdAt}) as trend_date,
          ${topicClassifications.topic},
          COUNT(*) as count,
          AVG(${topicClassifications.confidence}) as avg_confidence
        FROM ${topicClassifications}
        WHERE ${topicClassifications.organizationId} = ${org.id}
          AND ${topicClassifications.createdAt} >= ${yesterday}
          AND ${topicClassifications.createdAt} < ${today}
        GROUP BY DATE(${topicClassifications.createdAt}), ${topicClassifications.topic}
      `);

      // Aggregate sentiment trends
      const sentimentAgg = await db.execute(sql`
        SELECT
          DATE(sm.created_at) as trend_date,
          tc.sentiment->>'tone' as tone,
          tc.sentiment->>'riskLevel' as risk_level,
          COUNT(*) as count
        FROM ${suggestionMetrics} sm
        JOIN ${topicClassifications} tc ON tc.suggestion_id = sm.suggestion_id
        WHERE sm.organization_id = ${org.id}
          AND sm.created_at >= ${yesterday}
          AND sm.created_at < ${today}
        GROUP BY DATE(sm.created_at), tc.sentiment->>'tone', tc.sentiment->>'riskLevel'
      `);

      // Count escalations
      const escalationCount = await db.execute(sql`
        SELECT
          DATE(${escalationAlerts.createdAt}) as trend_date,
          ${escalationAlerts.severity},
          COUNT(*) as count
        FROM ${escalationAlerts}
        WHERE ${escalationAlerts.organizationId} = ${org.id}
          AND ${escalationAlerts.createdAt} >= ${yesterday}
          AND ${escalationAlerts.createdAt} < ${today}
        GROUP BY DATE(${escalationAlerts.createdAt}), ${escalationAlerts.severity}
      `);

      // Identify channel hotspots (channels with high complaint rate or escalations)
      const channelHotspots = await db.execute(sql`
        SELECT
          sm.channel_id,
          COUNT(*) FILTER (WHERE tc.topic = 'complaint') as complaint_count,
          COUNT(*) FILTER (WHERE tc.topic = 'escalation') as escalation_count,
          COUNT(*) as total_count,
          (COUNT(*) FILTER (WHERE tc.topic IN ('complaint', 'escalation'))::float / COUNT(*)) as hotspot_ratio
        FROM ${suggestionMetrics} sm
        JOIN ${topicClassifications} tc ON tc.suggestion_id = sm.suggestion_id
        WHERE sm.organization_id = ${org.id}
          AND sm.created_at >= ${yesterday}
          AND sm.created_at < ${today}
          AND sm.channel_id IS NOT NULL
        GROUP BY sm.channel_id
        HAVING COUNT(*) FILTER (WHERE tc.topic IN ('complaint', 'escalation'))::float / COUNT(*) > 0.3
      `);

      // Insert aggregated trends into communication_trends table
      await db.insert(communicationTrends).values({
        organizationId: org.id,
        trendDate: yesterday,
        trendPeriod: 'daily',
        topicDistribution: topicAgg as any, // JSONB
        sentimentDistribution: sentimentAgg as any,
        escalationCounts: escalationCount as any,
        channelHotspots: channelHotspots as any,
      });

      logger.info({ organizationId: org.id }, 'Daily trends aggregated');
    } catch (error) {
      logger.error({ error, organizationId: org.id }, 'Failed to aggregate trends');
    }
  }

  logger.info('Trend aggregation complete');
}, {
  connection: redis,
  concurrency: 5, // Process up to 5 orgs in parallel
});
```

### Pattern 3: Period-Over-Period Comparison Queries
**What:** Compare this week vs last week, this month vs last month for all metrics
**When to use:** Trend analysis showing if patterns are improving or worsening

**Example:**
```typescript
// Source: PostgreSQL window functions for period-over-period
// https://www.postgresql.org/docs/current/tutorial-window.html

// apps/web-portal/lib/admin/communication-insights.ts

import { sql } from 'drizzle-orm';
import { db, communicationTrends } from '../db';

export interface PeriodComparison {
  currentPeriod: {
    startDate: string;
    endDate: string;
    topicCounts: Record<string, number>;
    escalationRate: number;
  };
  previousPeriod: {
    startDate: string;
    endDate: string;
    topicCounts: Record<string, number>;
    escalationRate: number;
  };
  changePercent: {
    topicCounts: Record<string, number>; // Percent change per topic
    escalationRate: number;
  };
}

export async function getWeekOverWeekComparison(
  organizationId: string
): Promise<PeriodComparison> {
  // This week (Mon-Sun)
  const today = new Date();
  const thisWeekStart = new Date(today);
  thisWeekStart.setDate(today.getDate() - today.getDay()); // Last Monday
  thisWeekStart.setHours(0, 0, 0, 0);

  const thisWeekEnd = new Date(thisWeekStart);
  thisWeekEnd.setDate(thisWeekStart.getDate() + 7);

  // Last week
  const lastWeekStart = new Date(thisWeekStart);
  lastWeekStart.setDate(thisWeekStart.getDate() - 7);

  const lastWeekEnd = new Date(thisWeekStart);

  // Query with window function for comparison
  const result = await db.execute(sql`
    WITH this_week AS (
      SELECT
        topic_distribution,
        escalation_counts
      FROM ${communicationTrends}
      WHERE organization_id = ${organizationId}
        AND trend_date >= ${lastWeekStart}
        AND trend_date < ${lastWeekEnd}
    ),
    last_week AS (
      SELECT
        topic_distribution,
        escalation_counts
      FROM ${communicationTrends}
      WHERE organization_id = ${organizationId}
        AND trend_date >= ${lastWeekStart}
        AND trend_date < ${lastWeekEnd}
    )
    SELECT
      'this_week' as period,
      SUM((topic_distribution->>'complaint')::int) as complaint_count,
      SUM((topic_distribution->>'escalation')::int) as escalation_count,
      COUNT(*) as total_days
    FROM this_week
    UNION ALL
    SELECT
      'last_week' as period,
      SUM((topic_distribution->>'complaint')::int) as complaint_count,
      SUM((topic_distribution->>'escalation')::int) as escalation_count,
      COUNT(*) as total_days
    FROM last_week
  `);

  // Calculate percent changes
  // (Implementation details based on result structure)

  return {
    currentPeriod: { /* parsed from result */ },
    previousPeriod: { /* parsed from result */ },
    changePercent: { /* calculated */ },
  };
}
```

### Pattern 4: Channel Hotspot Detection
**What:** Identify channels with unusually high complaint/escalation rates
**When to use:** Proactive monitoring to surface problem areas before they blow up

**Example:**
```typescript
// Hotspot detection with statistical thresholds

export interface ChannelHotspot {
  channelId: string;
  channelName: string;
  totalMessages: number;
  complaintCount: number;
  escalationCount: number;
  complaintRate: number; // Percentage
  riskScore: number; // 0-100 composite score
  trendDirection: 'increasing' | 'stable' | 'decreasing';
}

export async function getChannelHotspots(
  organizationId: string,
  days: number = 7
): Promise<ChannelHotspot[]> {
  const startDate = new Date();
  startDate.setDate(startDate.getDate() - days);

  const result = await db.execute(sql`
    WITH channel_metrics AS (
      SELECT
        sm.channel_id,
        COUNT(*) as total_messages,
        COUNT(*) FILTER (WHERE tc.topic = 'complaint') as complaint_count,
        COUNT(*) FILTER (WHERE tc.topic = 'escalation') as escalation_count,
        COUNT(*) FILTER (WHERE (tc.sentiment->>'riskLevel')::text IN ('high', 'critical')) as high_risk_count
      FROM ${suggestionMetrics} sm
      JOIN ${topicClassifications} tc ON tc.suggestion_id = sm.suggestion_id
      WHERE sm.organization_id = ${organizationId}
        AND sm.created_at >= ${startDate}
        AND sm.channel_id IS NOT NULL
      GROUP BY sm.channel_id
    ),
    org_avg AS (
      SELECT
        AVG(complaint_count::float / total_messages) as avg_complaint_rate
      FROM channel_metrics
    )
    SELECT
      cm.channel_id,
      cm.total_messages,
      cm.complaint_count,
      cm.escalation_count,
      (cm.complaint_count::float / cm.total_messages * 100) as complaint_rate,
      (
        (cm.complaint_count::float / cm.total_messages - org_avg.avg_complaint_rate) * 50 +
        (cm.high_risk_count::float / cm.total_messages) * 50
      ) as risk_score
    FROM channel_metrics cm, org_avg
    WHERE (cm.complaint_count::float / cm.total_messages) > (org_avg.avg_complaint_rate * 1.5)  -- 50% above org average
       OR cm.escalation_count > 0  -- Any escalations
    ORDER BY risk_score DESC
    LIMIT 20
  `);

  // Calculate trend direction (compare last 3 days to previous 4 days)
  // (Additional query to determine if hotspot is getting worse)

  return result.rows.map(row => ({
    channelId: row.channel_id,
    channelName: '', // Look up from Slack API or cache
    totalMessages: row.total_messages,
    complaintCount: row.complaint_count,
    escalationCount: row.escalation_count,
    complaintRate: row.complaint_rate,
    riskScore: row.risk_score,
    trendDirection: 'stable', // From trend calculation
  }));
}
```

### Pattern 5: Tremor Visualizations for Communication Insights
**What:** Time-series charts, topic distribution donuts, hotspot heat maps
**When to use:** Admin dashboard showing communication patterns at-a-glance

**Example:**
```typescript
// Source: Tremor documentation and Phase 16 response-time-charts.tsx
// apps/web-portal/components/admin/communication-insights-charts.tsx

'use client';

import {
  Card,
  Title,
  LineChart,
  DonutChart,
  BarChart,
  AreaChart,
  Text,
} from '@tremor/react';

interface TopicTrendChartProps {
  data: Array<{
    date: string;
    scheduling: number;
    complaint: number;
    technical: number;
    status_update: number;
    request: number;
    escalation: number;
    general: number;
  }>;
}

export function TopicTrendChart({ data }: TopicTrendChartProps) {
  return (
    <Card>
      <Title>Topic Distribution Over Time</Title>
      <Text>Daily message count by topic category</Text>
      <AreaChart
        data={data}
        index="date"
        categories={[
          'complaint',
          'escalation',
          'technical',
          'request',
          'scheduling',
          'status_update',
          'general',
        ]}
        colors={['red', 'orange', 'blue', 'green', 'indigo', 'purple', 'gray']}
        stack={true}
        showAnimation
        yAxisWidth={40}
      />
    </Card>
  );
}

interface SentimentTrendChartProps {
  data: Array<{
    date: string;
    positive: number;
    neutral: number;
    tense: number;
    frustrated: number;
    angry: number;
  }>;
}

export function SentimentTrendChart({ data }: SentimentTrendChartProps) {
  return (
    <Card>
      <Title>Sentiment Trend</Title>
      <Text>Communication tone distribution over time</Text>
      <LineChart
        data={data}
        index="date"
        categories={['angry', 'frustrated', 'tense', 'neutral', 'positive']}
        colors={['red', 'orange', 'yellow', 'blue', 'green']}
        showAnimation
        yAxisWidth={40}
        connectNulls
      />
    </Card>
  );
}

interface HotspotTableProps {
  hotspots: Array<{
    channelName: string;
    complaintRate: number;
    riskScore: number;
    trend: string;
  }>;
}

export function ChannelHotspotTable({ hotspots }: HotspotTableProps) {
  return (
    <Card>
      <Title>Channel Hotspots</Title>
      <Text>Channels with high complaint/escalation rates</Text>
      <table className="w-full mt-4">
        <thead>
          <tr className="border-b">
            <th className="text-left py-2">Channel</th>
            <th className="text-right py-2">Complaint Rate</th>
            <th className="text-right py-2">Risk Score</th>
            <th className="text-right py-2">Trend</th>
          </tr>
        </thead>
        <tbody>
          {hotspots.map((hotspot, i) => (
            <tr key={i} className="border-b">
              <td className="py-2">{hotspot.channelName}</td>
              <td className="text-right py-2">{hotspot.complaintRate.toFixed(1)}%</td>
              <td className="text-right py-2">
                <span
                  className={
                    hotspot.riskScore > 70
                      ? 'text-red-600 font-bold'
                      : hotspot.riskScore > 40
                      ? 'text-orange-600'
                      : 'text-yellow-600'
                  }
                >
                  {hotspot.riskScore.toFixed(0)}
                </span>
              </td>
              <td className="text-right py-2">
                {hotspot.trend === 'increasing' ? 'üìà' : hotspot.trend === 'decreasing' ? 'üìâ' : '‚û°Ô∏è'}
              </td>
            </tr>
          ))}
        </tbody>
      </table>
    </Card>
  );
}
```

### Anti-Patterns to Avoid
- **Real-time aggregation for dashboard queries:** Always use precomputed trends table, not on-the-fly aggregation
- **Blocking suggestion generation for classification:** Topic classification MUST be fire-and-forget like sentiment
- **Single-level topic taxonomy:** Deep hierarchies (complaint ‚Üí billing ‚Üí wrong_charge) require multi-pass classification
- **Missing organizationId filter:** Every query must filter by org to prevent cross-tenant data leaks
- **Hourly aggregation jobs:** Daily is sufficient for communication patterns, hourly is storage overhead

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Topic classification | Regex keyword matching | Claude prompting with structured output | Handles context, synonyms, ambiguity better than keywords |
| Time-series aggregation | Loop through records and bucket | PostgreSQL date_trunc + GROUP BY | Database is faster, handles time zones, parallel execution |
| Trend detection | Simple percent change | Statistical thresholds (z-score, IQR) | Avoids false alarms from small sample sizes |
| Period calculations | Manual date math | date-fns (subDays, startOfWeek, etc.) | Handles DST, leap years, edge cases |
| Hotspot scoring | Linear weighted sum | Composite score with statistical normalization | Accounts for baseline rates and variance across orgs |

**Key insight:** Communication pattern detection is noisy. Use statistical methods (z-scores, control charts) to filter signal from noise, not just raw counts or percentages.

## Common Pitfalls

### Pitfall 1: Classification Prompt Drift
**What goes wrong:** Topic definitions aren't clear, Claude interprets categories inconsistently over time
**Why it happens:** Vague prompt like "classify as complaint or request" without examples
**How to avoid:** Provide EXPLICIT definitions with boundary examples in prompt (like sentiment prompt's risk level guidelines)
**Warning signs:** Same message classified differently on retries, category distribution shifts unexpectedly

**Example:**
```typescript
// BAD: Vague categories
"Classify as: scheduling, complaint, or other"

// GOOD: Explicit definitions with examples
"Topic definitions:
- scheduling: Meeting requests, calendar coordination, availability discussions
  Examples: 'Can we meet Tuesday?', 'What's your availability next week?'
- complaint: Issues, problems, dissatisfaction with service/product
  Examples: 'This isn't working', 'I'm frustrated with...', 'Why hasn't this been fixed?'
- technical: Tech support, how-to questions, troubleshooting
  Examples: 'How do I...?', 'Error when I try to...', 'Need help with...'"
```

### Pitfall 2: Aggregation Job Failure Handling
**What goes wrong:** Daily aggregation job fails silently, gaps appear in trend data
**Why it happens:** BullMQ retries configured but no monitoring/alerting
**How to avoid:** Add retry with exponential backoff, log to audit trail, alert on 3+ consecutive failures
**Warning signs:** Missing dates in trend charts, "no data available" despite active usage

**Example:**
```typescript
// Configure BullMQ retries and alerts
const trendQueue = new Queue('trend-aggregation', {
  connection: redis,
  defaultJobOptions: {
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 60000, // 1 min initial delay
    },
  },
});

// Worker with failure tracking
trendWorker.on('failed', async (job, error) => {
  logger.error({ jobId: job.id, error }, 'Trend aggregation failed');

  // Alert if 3+ consecutive failures
  const recentJobs = await trendQueue.getJobs(['failed'], 0, 3);
  const consecutiveFailures = recentJobs.filter(j =>
    j.finishedOn && Date.now() - j.finishedOn < 24 * 60 * 60 * 1000
  ).length;

  if (consecutiveFailures >= 3) {
    // Send alert to Slack or email
    await sendAdminAlert({
      subject: 'CRITICAL: Trend aggregation failing',
      message: `Aggregation job has failed ${consecutiveFailures} times in 24 hours`,
    });
  }
});
```

### Pitfall 3: Hotspot False Positives from Small Samples
**What goes wrong:** Channel with 5 messages, 2 complaints = 40% complaint rate ‚Üí flagged as hotspot, but it's just noise
**Why it happens:** Using raw percentages without considering sample size
**How to avoid:** Require minimum message threshold (e.g., 20 messages) and use statistical significance tests
**Warning signs:** Channels with 1-2 messages appearing in hotspot list, admins ignore alerts

**Example:**
```typescript
// Add minimum threshold and statistical test
const channelHotspots = await db.execute(sql`
  WITH channel_metrics AS (
    SELECT
      channel_id,
      COUNT(*) as total_messages,
      COUNT(*) FILTER (WHERE topic = 'complaint') as complaint_count
    FROM topic_classifications
    WHERE organization_id = ${orgId}
      AND created_at >= ${startDate}
    GROUP BY channel_id
    HAVING COUNT(*) >= 20  -- MINIMUM 20 MESSAGES
  ),
  org_stats AS (
    SELECT
      AVG(complaint_count::float / total_messages) as mean_complaint_rate,
      STDDEV(complaint_count::float / total_messages) as stddev_complaint_rate
    FROM channel_metrics
  )
  SELECT
    cm.channel_id,
    cm.complaint_count,
    cm.total_messages,
    (cm.complaint_count::float / cm.total_messages) as complaint_rate,
    -- Z-score: how many standard deviations above mean
    ((cm.complaint_count::float / cm.total_messages) - os.mean_complaint_rate) /
      NULLIF(os.stddev_complaint_rate, 0) as z_score
  FROM channel_metrics cm, org_stats os
  WHERE
    -- Require z-score > 2 (95% confidence) OR any escalations
    ((cm.complaint_count::float / cm.total_messages) - os.mean_complaint_rate) /
      NULLIF(os.stddev_complaint_rate, 0) > 2
  ORDER BY z_score DESC
`);
```

### Pitfall 4: Missing Client Context in Insights
**What goes wrong:** Communication insights show patterns but don't link to which clients are involved
**Why it happens:** Forgot to join with client profiles from Phase 12
**How to avoid:** Include client_id in aggregations, show "Client X has 3 hotspot channels" in dashboard
**Warning signs:** Admins say "these insights are interesting but I don't know which clients need attention"

**Example:**
```typescript
// Join client profiles into channel hotspots
const hotspotsWithClients = await db.execute(sql`
  SELECT
    ch.channel_id,
    ch.complaint_rate,
    ch.risk_score,
    cp.company_name as client_name,
    cp.id as client_id,
    COUNT(DISTINCT ch.channel_id) OVER (PARTITION BY cp.id) as client_hotspot_count
  FROM channel_hotspots ch
  LEFT JOIN ${clientProfiles} cp ON cp.organization_id = ${orgId}
    AND (cp.slack_channels @> ARRAY[ch.channel_id]::text[])  -- Client channels JSONB array contains this channel
  ORDER BY ch.risk_score DESC
`);

// Show client-level summary
const clientSummary = await db.execute(sql`
  SELECT
    cp.company_name,
    COUNT(DISTINCT ch.channel_id) as hotspot_count,
    AVG(ch.risk_score) as avg_risk_score
  FROM channel_hotspots ch
  JOIN ${clientProfiles} cp ON cp.slack_channels @> ARRAY[ch.channel_id]::text[]
  WHERE cp.organization_id = ${orgId}
  GROUP BY cp.company_name
  HAVING COUNT(*) > 0
  ORDER BY avg_risk_score DESC
`);
```

### Pitfall 5: Period-Over-Period Comparison Edge Cases
**What goes wrong:** "This week vs last week" shows incomplete data on Monday morning (this week just started)
**Why it happens:** Didn't handle partial periods or weekend gaps
**How to avoid:** Annotate UI with "partial period" warning, exclude incomplete days from comparison
**Warning signs:** Dashboard shows misleading "90% drop this week" on Monday

**Example:**
```typescript
export async function getWeekOverWeekWithAnnotations(
  organizationId: string
): Promise<PeriodComparison & { warnings: string[] }> {
  const warnings: string[] = [];
  const today = new Date();
  const dayOfWeek = today.getDay(); // 0 = Sunday, 6 = Saturday

  // If it's early in the week, warn about partial data
  if (dayOfWeek <= 2) { // Sunday, Monday, Tuesday
    warnings.push(
      `This week has only ${dayOfWeek + 1} days of data. Comparison may not be meaningful.`
    );
  }

  // Check if last aggregation ran (should be within 36 hours)
  const lastAggregation = await db
    .select({ maxDate: sql<Date>`MAX(trend_date)` })
    .from(communicationTrends)
    .where(eq(communicationTrends.organizationId, organizationId));

  const hoursSinceAgg = (Date.now() - lastAggregation[0].maxDate.getTime()) / (1000 * 60 * 60);

  if (hoursSinceAgg > 36) {
    warnings.push(
      `Trend data is ${Math.round(hoursSinceAgg)} hours old. Recent activity not reflected.`
    );
  }

  const comparison = await calculateComparison(organizationId);

  return { ...comparison, warnings };
}
```

## Code Examples

Verified patterns from official sources:

### Topic Classifier Integration in Suggestion Pipeline
```typescript
// Source: Phase 12 sentiment detector integration pattern
// apps/slack-backend/src/workers/suggestion-generator.ts

import { classifyTopic, TopicClassification } from '../services/topic-classifier.js';
import { analyzeSentiment, SentimentAnalysis } from '../services/sentiment-detector.js';
import { db, topicClassifications, suggestionMetrics } from '@slack-speak/database';

async function processSuggestion(job: Job) {
  const { workspaceId, organizationId, userId, channelId, conversationMessages, targetMessage } = job.data;

  // 1. Generate AI suggestion (existing)
  const suggestion = await aiService.generateSuggestion({ /* ... */ });

  // 2. Fire-and-forget: Classify topic (NEVER blocks delivery)
  classifyTopic({ conversationMessages, targetMessage })
    .then(async (classification: TopicClassification) => {
      await db.insert(topicClassifications).values({
        organizationId,
        workspaceId,
        userId,
        channelId,
        suggestionId: suggestion.id,
        topic: classification.topic,
        confidence: classification.confidence,
        reasoning: classification.reasoning,
      });

      logger.info({
        suggestionId: suggestion.id,
        topic: classification.topic
      }, 'Topic classified');
    })
    .catch(error => {
      // NEVER throw - classification failure should not affect suggestion
      logger.warn({ error, suggestionId: suggestion.id }, 'Topic classification failed');
    });

  // 3. Fire-and-forget: Analyze sentiment (existing from Phase 12)
  analyzeSentiment({ conversationMessages, targetMessage })
    .then(async (sentiment: SentimentAnalysis) => {
      await db.update(topicClassifications)
        .set({ sentiment: sentiment as any }) // Store in same row
        .where(eq(topicClassifications.suggestionId, suggestion.id));
    })
    .catch(error => {
      logger.warn({ error, suggestionId: suggestion.id }, 'Sentiment analysis failed');
    });

  // 4. Deliver suggestion (existing)
  await deliverSuggestion(suggestion);
}
```

### BullMQ Repeatable Job Setup
```typescript
// Source: BullMQ official docs - Job Schedulers
// https://docs.bullmq.io/guide/job-schedulers

import { Queue, Worker, Job } from 'bullmq';
import { redis } from '../config/redis.js';

// Create queue for trend aggregation
export const trendQueue = new Queue('trend-aggregation', {
  connection: redis,
});

// Schedule repeatable job
export async function setupTrendAggregation() {
  // Remove any existing scheduler (idempotent setup)
  const repeatableJobs = await trendQueue.getRepeatableJobs();
  for (const job of repeatableJobs) {
    if (job.name === 'aggregate-daily-trends') {
      await trendQueue.removeRepeatableByKey(job.key);
    }
  }

  // Add daily scheduler at 3 AM
  await trendQueue.add(
    'aggregate-daily-trends',
    {}, // No payload needed
    {
      repeat: {
        pattern: '0 3 * * *', // Cron expression
      },
      jobId: 'trend-aggregator', // Prevent duplicates
    }
  );

  logger.info('Daily trend aggregation scheduled at 3 AM');
}

// Worker
export const trendWorker = new Worker(
  'trend-aggregation',
  async (job: Job) => {
    logger.info({ jobId: job.id, name: job.name }, 'Processing trend aggregation');

    await aggregateDailyTrends();

    return { success: true, date: new Date().toISOString() };
  },
  {
    connection: redis,
    concurrency: 1, // Only run one aggregation at a time
  }
);

trendWorker.on('completed', (job) => {
  logger.info({ jobId: job.id }, 'Trend aggregation completed');
});

trendWorker.on('failed', (job, error) => {
  logger.error({ jobId: job?.id, error }, 'Trend aggregation failed');
});
```

### PostgreSQL Aggregation with date_trunc
```typescript
// Source: Drizzle ORM raw SQL for complex aggregations
// https://orm.drizzle.team/docs/sql

import { sql } from 'drizzle-orm';
import { db, topicClassifications, suggestionMetrics } from '../db';

export async function aggregateTopicTrends(
  organizationId: string,
  startDate: Date,
  endDate: Date
): Promise<TopicTrendData[]> {
  const result = await db.execute(sql`
    SELECT
      DATE(${topicClassifications.createdAt}) as trend_date,
      ${topicClassifications.topic},
      COUNT(*) as message_count,
      AVG(${topicClassifications.confidence}) as avg_confidence,

      -- Sentiment breakdown for this topic
      COUNT(*) FILTER (
        WHERE (${topicClassifications.sentiment}->>'tone')::text = 'angry'
      ) as angry_count,
      COUNT(*) FILTER (
        WHERE (${topicClassifications.sentiment}->>'tone')::text = 'frustrated'
      ) as frustrated_count,

      -- User reach
      COUNT(DISTINCT ${topicClassifications.userId}) as unique_users,

      -- Channel spread
      COUNT(DISTINCT ${topicClassifications.channelId}) as unique_channels

    FROM ${topicClassifications}
    WHERE ${topicClassifications.organizationId} = ${organizationId}
      AND ${topicClassifications.createdAt} >= ${startDate}
      AND ${topicClassifications.createdAt} < ${endDate}
    GROUP BY DATE(${topicClassifications.createdAt}), ${topicClassifications.topic}
    ORDER BY trend_date DESC, message_count DESC
  `);

  return result.rows.map(row => ({
    date: row.trend_date.toISOString(),
    topic: row.topic,
    count: Number(row.message_count),
    avgConfidence: Number(row.avg_confidence),
    angryCount: Number(row.angry_count),
    frustratedCount: Number(row.frustrated_count),
    uniqueUsers: Number(row.unique_users),
    uniqueChannels: Number(row.unique_channels),
  }));
}
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Pre-trained ML models (scikit-learn) | LLM prompting (Claude, GPT-4) | 2024-2025 | Zero training data needed, handles nuance/context better |
| Real-time aggregation on query | Precomputed rollups (continuous aggregates) | 2023+ | 10-100x faster queries, enables real-time dashboards |
| D3.js custom charts | Tremor high-level components | 2024-2025 | Faster development, consistent design, less custom code |
| Manual cron jobs | BullMQ repeatable jobs | 2022+ | Better monitoring, retry logic, distributed execution |
| MySQL time-series | PostgreSQL with TimescaleDB | 2020+ | Better aggregation functions, window functions, JSONB support |

**Deprecated/outdated:**
- **Keyword-based classification:** LLM prompting handles synonyms, context, ambiguity far better
- **Real-time aggregation queries:** Precomputed trends are standard for dashboards now
- **Node-cron for scheduling:** BullMQ provides better infrastructure (retries, monitoring, distributed)
- **Separate time-series database:** PostgreSQL with proper indexing handles time-series well

## Open Questions

Things that couldn't be fully resolved:

1. **Topic taxonomy depth**
   - What we know: 7 top-level topics covers most communication patterns
   - What's unclear: Should escalation ‚Üí [threatening_legal, demanding_manager, threatening_churn] be subtopics?
   - Recommendation: Start with flat 7-topic taxonomy. Add hierarchy in Phase 18 if users request it based on actual usage patterns.

2. **Aggregation frequency trade-offs**
   - What we know: Daily aggregation at 3 AM is standard pattern
   - What's unclear: Should we also have hourly aggregates for "last 24 hours" real-time view?
   - Recommendation: Start with daily. If admins request real-time monitoring, add separate hourly aggregates for last 7 days only (rolling window).

3. **Statistical thresholds for hotspots**
   - What we know: Z-score > 2 (95% confidence) is common threshold
   - What's unclear: Should threshold be configurable per org? (Some orgs have naturally high complaint rates)
   - Recommendation: Start with fixed z-score > 2. Add org-specific threshold config in Phase 20 (configurable automation rules) if needed.

4. **Client-specific insights when no client profiles exist**
   - What we know: Phase 12 client profiles link clients to channels
   - What's unclear: How to show insights for orgs that don't use client profiles feature?
   - Recommendation: Make client-specific insights optional section that only appears if org has client profiles configured. Default view is workspace-level insights.

## Sources

### Primary (HIGH confidence)
- [Claude API Docs - Prompt Engineering](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/overview) - Topic classification prompt patterns
- [BullMQ Job Schedulers](https://docs.bullmq.io/guide/job-schedulers) - Repeatable jobs with cron expressions
- [BullMQ Repeat Strategies](https://docs.bullmq.io/guide/job-schedulers/repeat-strategies) - Cron vs interval patterns
- [PostgreSQL Window Functions Tutorial](https://www.postgresql.org/docs/current/tutorial-window.html) - Period-over-period comparisons
- [Drizzle ORM Raw SQL](https://orm.drizzle.team/docs/sql) - Complex aggregation queries
- [Tremor Charts Documentation](https://www.tremor.so/) - React dashboard charts
- [TimescaleDB Continuous Aggregates](https://www.timescale.com/) - Precomputed time-series rollups pattern

### Secondary (MEDIUM confidence)
- [Customer Service Text Classification (PeerJ)](https://peerj.com/articles/cs-1016/) - Topic taxonomy for customer service
- [Support Ticket Classification (Sentisum)](https://www.sentisum.com/library/automated-ticket-tagging) - Common categories and approaches
- [Better Stack BullMQ Guide](https://betterstack.com/community/guides/scaling-nodejs/bullmq-scheduled-tasks/) - Job scheduling patterns
- [Alibaba Cloud Time-Series Best Practices](https://www.alibabacloud.com/blog/best-practices-for-postgresql-time-series-database-design_599374) - PostgreSQL aggregation optimization
- [Phase 12 sentiment-detector.ts](apps/slack-backend/src/services/sentiment-detector.ts) - Existing Claude prompting pattern
- [Phase 16 response-time-analytics.ts](apps/web-portal/lib/admin/response-time-analytics.ts) - Existing aggregation query pattern

### Tertiary (LOW confidence)
- [Customer Complaint Classification Research (Nature)](https://www.nature.com/articles/s41598-021-91189-0) - Academic research, verify specifics
- [Shopify 2025 Performance Review](https://www.shopify.com) - Mentioned in web search but couldn't verify exact article

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - All libraries already in codebase, proven in previous phases
- Topic classification: HIGH - Same pattern as Phase 12 sentiment detection (verified working)
- Aggregation patterns: HIGH - Based on PostgreSQL/Drizzle best practices and existing Phase 16 code
- Topic taxonomy: MEDIUM - 7 categories are standard for customer service, but needs validation with real data
- Hotspot detection: MEDIUM - Statistical thresholds (z-score) are standard, but tuning may be needed per org
- Real-time vs daily aggregation: MEDIUM - Daily is sufficient for most use cases, but some orgs may want hourly

**Research date:** 2026-02-04
**Valid until:** 60 days (stable domain, libraries, and patterns)
