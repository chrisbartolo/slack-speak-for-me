# Phase 2.1: Testing Infrastructure - Research

**Researched:** 2026-01-26
**Domain:** Testing (TypeScript/Node.js/Slack Bolt applications)
**Confidence:** HIGH

## Summary

Testing infrastructure for TypeScript Node.js applications has evolved significantly, with **Vitest** emerging as the dominant framework in 2026 due to its native TypeScript/ESM support, 10-20x faster performance than Jest, and seamless Vite integration. For Slack Bolt apps specifically, testing requires **mocking external APIs** (Slack API, Anthropic Claude API) rather than making live calls, with the community recommendation being unit testing with mocked internals since Bolt lacks official testing support.

The standard approach for database testing has shifted from Testcontainers to **PGlite** (WASM-compiled Postgres running in-memory) which eliminates Docker overhead while providing real PostgreSQL behavior. For external API mocking, **MSW (Mock Service Worker)** has become the de-facto standard, intercepting HTTP requests at the network level with reusable handlers across all test types.

The recommended testing strategy for this Slack app involves: (1) Unit tests with MSW for API mocking achieving 90%+ coverage, (2) Integration tests using PGlite for database operations and BullMQ job processing, (3) E2E tests validating complete flows, and (4) A custom `/test` route serving an interactive UI for manual testing without Slack.

**Primary recommendation:** Use Vitest with PGlite for database tests, MSW for API mocking, and build a simple Express-served HTML page at `/test` for manual testing scenarios.

## Standard Stack

The established libraries/tools for TypeScript Node.js testing in 2026:

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| **Vitest** | 3.2+ | Testing framework | 10-20x faster than Jest, native TypeScript/ESM support, browser-native design, seamless monorepo support with `projects` config |
| **@vitest/coverage-v8** | Latest | Code coverage | Native V8 coverage (faster than Istanbul), integrated threshold enforcement, HTML reports |
| **MSW (Mock Service Worker)** | 2.x | HTTP request mocking | Network-level interception, reusable across test types, supports REST/GraphQL, framework-agnostic |
| **PGlite** | Latest | In-memory PostgreSQL | WASM-compiled Postgres under 3MB, real Postgres behavior, no Docker overhead, instant startup |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| **@testcontainers/postgresql** | Latest | Docker-based PostgreSQL | Only if Docker is already in CI/CD pipeline and PGlite won't work for specific needs |
| **supertest** | Latest | HTTP endpoint testing | Testing Express routes directly, E2E API testing without browser |
| **@slack-wrench/jest-bolt-receiver** | Latest | Slack Bolt testing helpers | If using Jest instead of Vitest (deprecated approach) |
| **Playwright** | Latest | E2E browser testing | Only if testing browser-based UI components (not needed for API-only testing) |
| **@hyperse/vitest-coverage-reporter** | Latest | Coverage reporting | Enhanced coverage visualization, optional enhancement |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Vitest | Jest | Jest is more established (2026 version 30+) but 10-20x slower, requires more config for TypeScript/ESM, lacks native Vite integration |
| PGlite | Testcontainers | Testcontainers provides full Docker PostgreSQL but is slower (seconds vs milliseconds), blocks parallel test execution, requires Docker in CI |
| MSW | Nock | Nock is lower-level (intercepts Node's http module) but less maintainable, doesn't work in browser, lacks GraphQL support |
| Vitest | Node.js native test runner | Native runner is lightweight but lacks coverage, watch mode, UI, and mature ecosystem |

**Installation:**
```bash
# Root workspace
npm install -D vitest @vitest/coverage-v8 @vitest/ui

# Backend app workspace
cd apps/slack-backend
npm install -D vitest @vitest/coverage-v8 msw @electric-sql/pglite supertest
npm install -D @types/supertest

# Database package (for PGlite integration)
cd packages/database
npm install -D @electric-sql/pglite
```

## Architecture Patterns

### Recommended Project Structure
```
apps/slack-backend/
├── src/
│   ├── services/
│   │   ├── ai.ts
│   │   ├── ai.test.ts              # Unit tests alongside source
│   │   ├── watch.ts
│   │   ├── watch.test.ts
│   │   └── ...
│   ├── handlers/
│   │   ├── events/
│   │   │   ├── app-mention.ts
│   │   │   └── app-mention.test.ts
│   │   └── ...
│   ├── routes/
│   │   └── test.ts                 # Manual testing UI route
│   └── ...
├── test/
│   ├── setup.ts                    # Vitest global setup
│   ├── helpers/
│   │   ├── db.ts                   # PGlite database helpers
│   │   ├── mocks.ts                # Shared mock data
│   │   └── slack-client.ts         # Slack client test helpers
│   ├── integration/
│   │   ├── database.test.ts        # Database integration tests
│   │   ├── job-queue.test.ts       # BullMQ worker tests
│   │   └── oauth.test.ts           # OAuth flow tests
│   └── e2e/
│       ├── app-mention.e2e.test.ts # End-to-end flow tests
│       └── suggestion.e2e.test.ts
├── vitest.config.ts                # Test configuration
└── package.json

packages/database/
├── src/
│   ├── schema.ts
│   └── index.ts
├── test/
│   ├── setup.ts                    # PGlite setup for DB tests
│   └── schema.test.ts
└── vitest.config.ts

.github/
└── workflows/
    └── test.yml                    # CI/CD test workflow
```

### Pattern 1: Unit Testing Services with MSW

**What:** Test individual service functions with mocked external API calls using MSW
**When to use:** Testing services/ai.ts, services/context.ts, any code making HTTP requests

**Example:**
```typescript
// Source: https://mswjs.io/docs/getting-started + https://vitest.dev/guide/mocking
// test/setup.ts
import { beforeAll, afterEach, afterAll } from 'vitest'
import { setupServer } from 'msw/node'
import { http, HttpResponse } from 'msw'

// Define handlers for Anthropic API
export const handlers = [
  http.post('https://api.anthropic.com/v1/messages', () => {
    return HttpResponse.json({
      id: 'msg_123',
      type: 'message',
      role: 'assistant',
      content: [{ type: 'text', text: 'Mocked AI response' }],
    })
  }),

  // Slack API handlers
  http.post('https://slack.com/api/chat.postEphemeral', () => {
    return HttpResponse.json({ ok: true, ts: '1234567890.123456' })
  }),

  http.post('https://slack.com/api/conversations.history', () => {
    return HttpResponse.json({
      ok: true,
      messages: [{ text: 'Test message', ts: '1234567890.123456' }],
    })
  }),
]

export const server = setupServer(...handlers)

beforeAll(() => server.listen({ onUnhandledRequest: 'warn' }))
afterEach(() => server.resetHandlers())
afterAll(() => server.close())

// src/services/ai.test.ts
import { describe, it, expect, beforeEach } from 'vitest'
import { server } from '../../test/setup'
import { http, HttpResponse } from 'msw'
import { generateSuggestion } from './ai'

describe('AI Service', () => {
  it('should generate suggestion from Claude API', async () => {
    const result = await generateSuggestion({
      context: 'User asked about pricing',
      prompt: 'Generate professional response'
    })

    expect(result).toBe('Mocked AI response')
  })

  it('should handle API errors gracefully', async () => {
    // Override handler for this test
    server.use(
      http.post('https://api.anthropic.com/v1/messages', () => {
        return HttpResponse.json(
          { error: { message: 'Rate limit exceeded' } },
          { status: 429 }
        )
      })
    )

    await expect(
      generateSuggestion({ context: 'test', prompt: 'test' })
    ).rejects.toThrow('Rate limit exceeded')
  })
})
```

### Pattern 2: Database Integration Tests with PGlite

**What:** Test database operations using real PostgreSQL in-memory via PGlite
**When to use:** Testing packages/database operations, services that query the database

**Example:**
```typescript
// Source: https://github.com/rphlmr/drizzle-vitest-pg + https://dev.to/benjamindaniel/how-to-test-your-nodejs-postgres-app-using-drizzle-pglite-4fb3
// packages/database/test/setup.ts
import { beforeEach } from 'vitest'
import { PGlite } from '@electric-sql/pglite'
import { drizzle } from 'drizzle-orm/pglite'
import { migrate } from 'drizzle-orm/pglite/migrator'
import * as schema from '../src/schema'

let pgLite: PGlite

export async function setupTestDb() {
  // Create new in-memory database for each test file
  pgLite = new PGlite()
  const db = drizzle(pgLite, { schema })

  // Apply migrations (use push for tests, not migrate)
  await migrate(db, { migrationsFolder: './drizzle' })

  return db
}

export async function cleanupTestDb() {
  await pgLite.close()
}

// test/integration/database.test.ts
import { describe, it, expect, beforeEach, afterEach } from 'vitest'
import { setupTestDb, cleanupTestDb } from '../../test/helpers/db'
import { installations, suggestions } from '../src/schema'

describe('Database Operations', () => {
  let db: ReturnType<typeof setupTestDb>

  beforeEach(async () => {
    db = await setupTestDb()
  })

  afterEach(async () => {
    await cleanupTestDb()
  })

  it('should insert and retrieve installation', async () => {
    const installation = {
      teamId: 'T123',
      accessToken: 'xoxb-token',
      scope: 'chat:write',
      botUserId: 'U123'
    }

    await db.insert(installations).values(installation)

    const result = await db.select()
      .from(installations)
      .where(eq(installations.teamId, 'T123'))

    expect(result).toHaveLength(1)
    expect(result[0].teamId).toBe('T123')
  })
})
```

### Pattern 3: BullMQ Job Testing with Real Redis

**What:** Test job queue workers using actual Redis instance (via Testcontainers or local Redis)
**When to use:** Testing jobs/workers.ts, async job processing

**Example:**
```typescript
// Source: https://medium.com/@vijaysinh.khot/testing-the-untestable-a-guide-to-integration-testing-bullmq-jobs-with-jest-736db303ca2e + https://docs.bullmq.io
// test/integration/job-queue.test.ts
import { describe, it, expect, beforeAll, afterAll } from 'vitest'
import { Queue, Worker, QueueEvents } from 'bullmq'
import { GenericContainer, StartedTestContainer } from 'testcontainers'

describe('BullMQ Job Processing', () => {
  let redisContainer: StartedTestContainer
  let queue: Queue
  let queueEvents: QueueEvents
  let connection: { host: string; port: number }

  beforeAll(async () => {
    // Start Redis container
    redisContainer = await new GenericContainer('redis:7-alpine')
      .withExposedPorts(6379)
      .start()

    connection = {
      host: redisContainer.getHost(),
      port: redisContainer.getMappedPort(6379),
    }

    queue = new Queue('suggestion-generation', { connection })
    queueEvents = new QueueEvents('suggestion-generation', { connection })
  })

  afterAll(async () => {
    await queue.close()
    await queueEvents.close()
    await redisContainer.stop()
  })

  it('should process suggestion generation job', async () => {
    const worker = new Worker(
      'suggestion-generation',
      async (job) => {
        // Process job
        return { suggestion: `Processed: ${job.data.text}` }
      },
      { connection }
    )

    const job = await queue.add('generate', {
      text: 'Test message',
      userId: 'U123'
    })

    // Wait for job completion
    const result = await new Promise((resolve) => {
      queueEvents.on('completed', ({ jobId, returnvalue }) => {
        if (jobId === job.id) resolve(returnvalue)
      })
    })

    expect(result).toMatchObject({
      suggestion: 'Processed: Test message'
    })

    await worker.close()
  })
})
```

### Pattern 4: E2E Testing Complete Flows

**What:** Test entire user flows from Slack event → processing → response
**When to use:** Validating critical paths work end-to-end

**Example:**
```typescript
// Source: Composite pattern from Vitest + Supertest docs
// test/e2e/app-mention.e2e.test.ts
import { describe, it, expect, beforeAll } from 'vitest'
import request from 'supertest'
import { app } from '../../src/app' // Express app instance
import { setupTestDb } from '../helpers/db'

describe('App Mention E2E', () => {
  let db: any

  beforeAll(async () => {
    db = await setupTestDb()
    // Seed test data
  })

  it('should handle app_mention event and deliver suggestion', async () => {
    const slackEvent = {
      type: 'event_callback',
      event: {
        type: 'app_mention',
        user: 'U123',
        text: '<@BOT> help me respond',
        channel: 'C123',
        ts: '1234567890.123456',
      },
    }

    // Mock Slack signature verification
    const response = await request(app)
      .post('/slack/events')
      .set('X-Slack-Signature', 'v0=mock-signature')
      .set('X-Slack-Request-Timestamp', String(Date.now() / 1000))
      .send(slackEvent)
      .expect(200)

    // Verify job was queued
    const jobs = await queue.getJobs(['waiting', 'active'])
    expect(jobs).toHaveLength(1)

    // Wait for job processing
    await waitForJobCompletion(jobs[0].id)

    // Verify ephemeral message was sent (mocked via MSW)
    // Check that chat.postEphemeral was called
  })
})
```

### Pattern 5: Manual Testing UI

**What:** Build Express route serving HTML page for testing handlers without Slack
**When to use:** Manual testing, debugging, demonstrating functionality

**Example:**
```typescript
// Source: Combined from Express patterns and testing best practices
// src/routes/test.ts
import { Router } from 'express'
import { app as boltApp } from '../app' // Bolt app instance

const router = Router()

router.get('/test', (req, res) => {
  res.send(`
    <!DOCTYPE html>
    <html>
    <head>
      <title>Slack App Testing</title>
      <style>
        body { font-family: sans-serif; max-width: 1200px; margin: 50px auto; }
        .test-section { margin: 30px 0; padding: 20px; border: 1px solid #ccc; }
        button { padding: 10px 20px; margin: 5px; cursor: pointer; }
        textarea { width: 100%; height: 100px; }
        .result { background: #f5f5f5; padding: 10px; margin-top: 10px; }
      </style>
    </head>
    <body>
      <h1>Slack App Testing Interface</h1>

      <div class="test-section">
        <h2>Test app_mention Event</h2>
        <input type="text" id="mention-user" placeholder="User ID (U123)" value="U123" />
        <input type="text" id="mention-channel" placeholder="Channel ID (C123)" value="C123" />
        <textarea id="mention-text" placeholder="Message text">@bot help me respond to this</textarea>
        <button onclick="testAppMention()">Send app_mention</button>
        <div id="mention-result" class="result"></div>
      </div>

      <div class="test-section">
        <h2>Test AI Generation</h2>
        <textarea id="ai-context" placeholder="Context">Customer asking about pricing</textarea>
        <textarea id="ai-prompt" placeholder="Prompt">Generate professional response</textarea>
        <button onclick="testAI()">Generate Suggestion</button>
        <div id="ai-result" class="result"></div>
      </div>

      <div class="test-section">
        <h2>Test Message Event</h2>
        <input type="text" id="msg-channel" placeholder="Channel ID" value="C123" />
        <textarea id="msg-text" placeholder="Message">This is a test message</textarea>
        <button onclick="testMessage()">Send Message Event</button>
        <div id="msg-result" class="result"></div>
      </div>

      <script>
        async function testAppMention() {
          const result = await fetch('/api/test/app-mention', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              user: document.getElementById('mention-user').value,
              channel: document.getElementById('mention-channel').value,
              text: document.getElementById('mention-text').value,
            })
          }).then(r => r.json())

          document.getElementById('mention-result').textContent =
            JSON.stringify(result, null, 2)
        }

        async function testAI() {
          const result = await fetch('/api/test/ai', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              context: document.getElementById('ai-context').value,
              prompt: document.getElementById('ai-prompt').value,
            })
          }).then(r => r.json())

          document.getElementById('ai-result').textContent =
            JSON.stringify(result, null, 2)
        }

        async function testMessage() {
          const result = await fetch('/api/test/message', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              channel: document.getElementById('msg-channel').value,
              text: document.getElementById('msg-text').value,
            })
          }).then(r => r.json())

          document.getElementById('msg-result').textContent =
            JSON.stringify(result, null, 2)
        }
      </script>
    </body>
    </html>
  `)
})

// Test API endpoints that call handlers directly
router.post('/api/test/app-mention', async (req, res) => {
  try {
    // Call Bolt handler directly without Slack
    const result = await simulateAppMentionEvent(req.body)
    res.json({ success: true, result })
  } catch (error) {
    res.status(500).json({ success: false, error: error.message })
  }
})

router.post('/api/test/ai', async (req, res) => {
  try {
    const { context, prompt } = req.body
    const suggestion = await generateSuggestion({ context, prompt })
    res.json({ success: true, suggestion })
  } catch (error) {
    res.status(500).json({ success: false, error: error.message })
  }
})

export default router
```

### Anti-Patterns to Avoid

- **Testing Implementation Details**: Don't test internal function calls or private methods - test behavior and outputs instead. If refactoring breaks tests without changing behavior, tests are too coupled.

- **Excessive Mocking**: Don't mock everything - use real PostgreSQL via PGlite for database tests. Mocking the database hides issues like type mismatches, constraint violations, and query performance.

- **Testing Non-Units in Unit Tests**: Don't make real HTTP calls to Slack/Anthropic APIs in unit tests - these are integration/E2E tests. Unit tests should be fast (<100ms) and never depend on external services.

- **No Test Data Cleanup**: Don't leave test data in Redis or shared databases between tests - each test should be isolated. Use `beforeEach` to reset state, not just `beforeAll`.

- **Single Test, Multiple Scenarios**: Don't test multiple things in one test (e.g., testing both success and error cases together) - split into separate tests for better failure diagnosis.

- **Hard-Coded Test Data**: Don't use production IDs or tokens in tests - use factories or fixtures to generate consistent test data.

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| HTTP request mocking | Custom mock functions per test, monkey-patching fetch | **MSW (Mock Service Worker)** | Handles request matching, response formatting, TypeScript types, can be reused across unit/integration/E2E tests, works in Node and browser |
| In-memory database | Mocking database methods, using SQLite | **PGlite** | Real PostgreSQL behavior (not SQLite quirks), runs in WASM, <3MB, instant startup, supports parallel tests |
| Test coverage reporting | Parsing test output, custom scripts | **@vitest/coverage-v8** + **vitest-coverage-report-action** (GitHub) | Native V8 coverage (accurate), HTML reports, threshold enforcement, PR comments with coverage diff |
| Slack signature verification | Custom crypto implementation | **@slack/bolt** built-in verification | Bolt handles HMAC-SHA256 signature verification automatically, timing-safe comparison, easy to disable for tests |
| Test data factories | Manual object creation in every test | **@faker-js/faker** or **fishery** | Generates realistic random data, reduces test brittleness from hard-coded values, TypeScript support |
| Async test waiting | `setTimeout` or polling loops | **vi.waitFor()** or **QueueEvents** (BullMQ) | Vitest's waitFor provides proper async waiting with timeout/polling control. BullMQ's QueueEvents emit job completion events. |
| HTTP endpoint testing | Manual http module calls | **supertest** | Chainable API, automatic server lifecycle, response assertions, works with Express/Bolt |
| Date/time mocking | Overriding Date.now | **vi.useFakeTimers()** | Vitest's fake timers mock Date, setTimeout, setInterval consistently, can advance time programmatically |

**Key insight:** Testing has many subtle edge cases (race conditions, proper cleanup, TypeScript types, parallel execution). Using battle-tested libraries prevents bugs in your tests and makes them more maintainable. The Slack ecosystem specifically lacks official test tooling, so standardize on MSW + supertest for API testing.

## Common Pitfalls

### Pitfall 1: Slack Signature Verification Breaking Tests

**What goes wrong:** Real Slack events require cryptographic signature verification (HMAC-SHA256). Tests fail with "invalid_signature" errors because test events lack valid signatures.

**Why it happens:** Bolt automatically verifies `X-Slack-Signature` header matches HMAC of request body + timestamp + signing secret. Test data doesn't include valid signatures.

**How to avoid:**
- Disable signature verification in test environment: `app = new App({ signingSecret: 'test-secret', processBeforeResponse: true, socketMode: false, developerMode: true })`
- Use environment variable: `SLACK_SKIP_SIGNATURE_VERIFICATION=true` (Bolt respects this)
- For E2E tests, generate valid signatures using signing secret

**Warning signs:**
- Tests fail with "invalid_signature" errors
- Need to pass real Slack tokens to tests
- Tests can only run against live Slack workspace

**Example fix:**
```typescript
// test/setup.ts
process.env.SLACK_SKIP_SIGNATURE_VERIFICATION = 'true'

// Or in test
import { App } from '@slack/bolt'
const app = new App({
  signingSecret: 'test-secret',
  token: 'xoxb-test-token',
  developerMode: true, // Disables signature verification
})
```

### Pitfall 2: Database Migrations in Tests Are Too Slow

**What goes wrong:** Running `drizzle-kit migrate` before each test makes tests take 30+ seconds. CI times out or developers skip running tests.

**Why it happens:** Migration tools read files, connect to database, run SQL sequentially. Designed for production deploys, not test speed.

**How to avoid:**
- Use `drizzle-kit push` instead of `migrate` for tests (pushes schema directly, no migration files)
- With PGlite, create schema once in `beforeAll`, then clone in-memory database for each test
- Or use database template cloning: create template DB with schema in global setup, then clone per test

**Warning signs:**
- Test suite takes >30 seconds for <100 tests
- "Waiting for database" messages in test output
- Developers complain tests are too slow to run locally

**Example fix:**
```typescript
// test/helpers/db.ts
import { PGlite } from '@electric-sql/pglite'
import { drizzle } from 'drizzle-orm/pglite'
import { push } from 'drizzle-orm/pglite/migrator' // Not migrate!

export async function setupTestDb() {
  const pgLite = new PGlite()
  const db = drizzle(pgLite)

  // Push schema directly - much faster than migrate
  await push(db, { schema: './src/schema.ts' })

  return db
}
```

### Pitfall 3: Tests Pass Locally But Fail in CI

**What goes wrong:** Tests succeed on developer machines but fail in GitHub Actions or other CI. Usually database or Redis connection issues.

**Why it happens:**
- Local tests use developer's PostgreSQL/Redis instance
- CI doesn't have same services available, or uses different ports/credentials
- Race conditions with parallel test execution in CI

**How to avoid:**
- Use PGlite for database (no external service needed)
- For Redis (BullMQ), use Testcontainers to start Redis automatically in CI
- Set up proper test environment detection: `if (process.env.CI) { /* use containers */ }`
- Don't rely on hardcoded ports - use dynamic port allocation

**Warning signs:**
- "ECONNREFUSED" or "Connection timeout" errors in CI
- Tests fail with "Database not found" in CI but work locally
- Intermittent failures that don't reproduce locally

**Example fix:**
```typescript
// vitest.config.ts
import { defineConfig } from 'vitest/config'

export default defineConfig({
  test: {
    // Run tests serially in CI to avoid race conditions
    pool: process.env.CI ? 'forks' : 'threads',
    poolOptions: {
      threads: {
        singleThread: process.env.CI === 'true',
      },
    },
    // Longer timeout in CI (slower machines)
    testTimeout: process.env.CI ? 30000 : 10000,
  },
})
```

### Pitfall 4: Mocking Too Much vs. Not Enough

**What goes wrong:**
- Over-mocking: Tests pass but production breaks because mocks don't match real API behavior
- Under-mocking: Tests make real API calls, use up quota, are slow, fail due to network issues

**Why it happens:** Unclear boundaries between unit/integration/E2E tests and what should be mocked at each level.

**How to avoid:**
- **Unit tests**: Mock external APIs (Slack, Anthropic, Redis) - test business logic only
- **Integration tests**: Use real database (PGlite), real job queue (Testcontainers Redis), mock external HTTP APIs
- **E2E tests**: Everything real except maybe external APIs (use staging APIs if available)
- Document what's mocked in each test file

**Warning signs:**
- Unit tests take >5 seconds to run
- API quota exceeded during test runs
- Tests fail when internet is down
- Production bugs that tests didn't catch because behavior was mocked incorrectly

**Example fix:**
```typescript
// test/unit/services/ai.test.ts
// ✅ GOOD: Mock external Anthropic API
import { server } from '../../setup' // MSW
import { generateSuggestion } from './ai'

// test/integration/database.test.ts
// ✅ GOOD: Real database (PGlite), mocked external APIs
import { setupTestDb } from '../helpers/db'
import { server } from '../setup' // Still mock Anthropic/Slack

// test/e2e/app-mention.e2e.test.ts
// ✅ GOOD: Real database, real Redis, mocked external APIs (or use staging)
import { setupTestDb } from '../helpers/db'
import { GenericContainer } from 'testcontainers'
```

### Pitfall 5: Not Testing Error Cases

**What goes wrong:** Tests only cover happy path. Production encounters API errors, rate limits, network timeouts, and crashes because error handling is broken.

**Why it happens:**
- Error cases are harder to test (need to simulate failures)
- Developers focus on making features work, not handling failures
- Mocks default to success responses

**How to avoid:**
- Write at least 1 error test for every happy path test
- Use MSW's `server.use()` to override handlers and simulate errors per-test
- Test specific errors: rate limits (429), server errors (500), network timeouts, invalid inputs
- Use `expect().rejects.toThrow()` for async error assertions

**Warning signs:**
- Test coverage high (90%+) but production has frequent crashes
- No tests contain `expect().rejects` or `try/catch`
- All MSW handlers return success responses

**Example fix:**
```typescript
// src/services/ai.test.ts
import { server } from '../../test/setup'
import { http, HttpResponse } from 'msw'

describe('AI Service - Error Cases', () => {
  it('should handle rate limit errors', async () => {
    server.use(
      http.post('https://api.anthropic.com/v1/messages', () => {
        return HttpResponse.json(
          { error: { type: 'rate_limit_error', message: 'Rate limit exceeded' } },
          { status: 429 }
        )
      })
    )

    await expect(generateSuggestion({ context: 'test' }))
      .rejects.toThrow('Rate limit exceeded')
  })

  it('should handle network timeouts', async () => {
    server.use(
      http.post('https://api.anthropic.com/v1/messages', async () => {
        await new Promise(resolve => setTimeout(resolve, 10000)) // Simulate timeout
        return HttpResponse.json({})
      })
    )

    await expect(generateSuggestion({ context: 'test' }))
      .rejects.toThrow('timeout')
  })

  it('should handle invalid API responses', async () => {
    server.use(
      http.post('https://api.anthropic.com/v1/messages', () => {
        return HttpResponse.json({ invalid: 'response' }) // Missing required fields
      })
    )

    await expect(generateSuggestion({ context: 'test' }))
      .rejects.toThrow()
  })
})
```

### Pitfall 6: Coverage Theater (High % But Low Quality)

**What goes wrong:** Tests hit 90%+ coverage target but don't actually validate behavior. Tests just call functions without assertions or test trivial code.

**Why it happens:**
- Coverage metrics incentivize quantity over quality
- Developers add tests just to hit threshold without thinking about what matters
- Easy to test getters/setters but skip complex logic

**How to avoid:**
- Review coverage reports manually - look for missing branches, not just lines
- Require meaningful assertions in every test (`expect(result).toBe()`, not just calling functions)
- Focus coverage on business logic (services, handlers), not boilerplate (types, constants)
- Use per-file thresholds: high for critical code, lower for utilities

**Warning signs:**
- Tests with no assertions (just function calls)
- 95% coverage but production bugs are common
- Coverage achieved by testing trivial code (getters, type guards)
- No integration or E2E tests, only unit tests

**Example fix:**
```typescript
// vitest.config.ts
export default defineConfig({
  test: {
    coverage: {
      provider: 'v8',
      thresholds: {
        // Global thresholds
        lines: 80,
        functions: 80,
        branches: 75,
        statements: 80,

        // Strict thresholds for critical code
        'src/services/**.ts': {
          lines: 90,
          functions: 90,
          branches: 85,
        },
        'src/handlers/**.ts': {
          lines: 90,
          functions: 90,
          branches: 85,
        },

        // Relaxed for utilities
        'src/utils/**.ts': {
          lines: 70,
        },
      },
      // Exclude trivial code from coverage
      exclude: [
        'src/**/*.types.ts',
        'src/**/index.ts', // Barrel exports
        'src/**/*.d.ts',
      ],
    },
  },
})
```

## Code Examples

Verified patterns from official sources:

### Vitest Configuration for Monorepo

```typescript
// Source: https://vitest.dev/guide/projects + https://turborepo.dev/docs/guides/tools/vitest
// vitest.config.ts (root)
import { defineConfig } from 'vitest/config'

export default defineConfig({
  test: {
    // Projects configuration for monorepo
    projects: [
      './apps/*/vitest.config.ts',
      './packages/*/vitest.config.ts',
    ],
  },
})

// apps/slack-backend/vitest.config.ts
import { defineConfig } from 'vitest/config'

export default defineConfig({
  test: {
    name: 'slack-backend',
    environment: 'node',
    setupFiles: ['./test/setup.ts'],
    coverage: {
      provider: 'v8',
      reporter: ['text', 'html', 'json-summary', 'json'],
      reportsDirectory: './coverage',
      thresholds: {
        lines: 90,
        functions: 90,
        branches: 85,
        statements: 90,
      },
      exclude: [
        'test/**',
        '**/*.test.ts',
        '**/*.spec.ts',
        'src/routes/test.ts', // Exclude manual test UI
      ],
    },
    // Parallel execution
    pool: 'threads',
    poolOptions: {
      threads: {
        singleThread: false,
      },
    },
  },
})

// packages/database/vitest.config.ts
import { defineConfig } from 'vitest/config'

export default defineConfig({
  test: {
    name: 'database',
    environment: 'node',
    setupFiles: ['./test/setup.ts'],
    coverage: {
      provider: 'v8',
      thresholds: {
        lines: 85,
        functions: 85,
        branches: 80,
        statements: 85,
      },
    },
  },
})
```

### MSW Setup for Node.js Tests

```typescript
// Source: https://mswjs.io/docs/getting-started + https://vitest.dev/guide/mocking
// test/setup.ts
import { beforeAll, afterEach, afterAll } from 'vitest'
import { setupServer } from 'msw/node'
import { http, HttpResponse } from 'msw'

// Define request handlers
export const handlers = [
  // Anthropic Claude API
  http.post('https://api.anthropic.com/v1/messages', async ({ request }) => {
    const body = await request.json()

    return HttpResponse.json({
      id: 'msg_test123',
      type: 'message',
      role: 'assistant',
      content: [{
        type: 'text',
        text: 'This is a mocked AI suggestion for testing'
      }],
      model: 'claude-3-5-sonnet-20241022',
      stop_reason: 'end_turn',
      usage: { input_tokens: 100, output_tokens: 50 }
    })
  }),

  // Slack API - chat.postEphemeral
  http.post('https://slack.com/api/chat.postEphemeral', async ({ request }) => {
    const body = await request.json()

    return HttpResponse.json({
      ok: true,
      message_ts: '1234567890.123456'
    })
  }),

  // Slack API - conversations.history
  http.post('https://slack.com/api/conversations.history', async ({ request }) => {
    const body = await request.json()

    return HttpResponse.json({
      ok: true,
      messages: [
        {
          type: 'message',
          user: 'U123',
          text: 'Previous message 1',
          ts: '1234567880.123456'
        },
        {
          type: 'message',
          user: 'U456',
          text: 'Previous message 2',
          ts: '1234567885.123456'
        }
      ],
      has_more: false
    })
  }),

  // Slack API - users.info
  http.post('https://slack.com/api/users.info', async ({ request }) => {
    const body = await request.json()

    return HttpResponse.json({
      ok: true,
      user: {
        id: body.user,
        name: 'testuser',
        real_name: 'Test User',
        is_bot: false
      }
    })
  }),
]

// Create server instance
export const server = setupServer(...handlers)

// Configure for tests
beforeAll(() => {
  server.listen({
    onUnhandledRequest: 'warn', // Warn about unmocked requests
  })
})

afterEach(() => {
  server.resetHandlers() // Reset to original handlers after each test
})

afterAll(() => {
  server.close() // Clean up after all tests
})

// Enable in vitest.config.ts
// setupFiles: ['./test/setup.ts']
```

### PGlite Database Setup for Tests

```typescript
// Source: https://github.com/rphlmr/drizzle-vitest-pg + https://dev.to/benjamindaniel/how-to-test-your-nodejs-postgres-app-using-drizzle-pglite-4fb3
// test/helpers/db.ts
import { PGlite } from '@electric-sql/pglite'
import { drizzle, type PgliteDatabase } from 'drizzle-orm/pglite'
import { migrate } from 'drizzle-orm/pglite/migrator'
import * as schema from '../../src/schema'

let pgLite: PGlite | null = null
let db: PgliteDatabase<typeof schema> | null = null

/**
 * Creates a new in-memory PostgreSQL database for testing.
 * Much faster than Testcontainers (milliseconds vs seconds).
 */
export async function setupTestDb() {
  // Create new in-memory PGlite instance
  pgLite = new PGlite()

  // Initialize Drizzle with schema
  db = drizzle(pgLite, { schema })

  // Push schema (faster than migrate for tests)
  // Note: Use drizzle-kit push, not migrate, in tests
  await migrate(db, { migrationsFolder: './drizzle' })

  return db
}

/**
 * Cleans up test database.
 */
export async function cleanupTestDb() {
  if (pgLite) {
    await pgLite.close()
    pgLite = null
    db = null
  }
}

/**
 * Gets current test database instance.
 * Throws if not initialized.
 */
export function getTestDb() {
  if (!db) {
    throw new Error('Test database not initialized. Call setupTestDb() first.')
  }
  return db
}

// Alternative: Shared DB with reset between tests (faster for many tests)
export async function setupSharedTestDb() {
  if (!db) {
    pgLite = new PGlite()
    db = drizzle(pgLite, { schema })
    await migrate(db, { migrationsFolder: './drizzle' })
  }
  return db
}

export async function resetTestDb() {
  if (!db) return

  // Delete all data from tables
  const tables = Object.values(schema)
  for (const table of tables) {
    if ('name' in table) {
      await db.delete(table as any)
    }
  }
}

// Usage in test file:
// import { beforeEach, afterEach, describe, it } from 'vitest'
// import { setupTestDb, cleanupTestDb } from './helpers/db'
//
// describe('Database tests', () => {
//   let db: any
//
//   beforeEach(async () => {
//     db = await setupTestDb()
//   })
//
//   afterEach(async () => {
//     await cleanupTestDb()
//   })
//
//   it('should work', async () => {
//     // Test with real PostgreSQL behavior
//   })
// })
```

### GitHub Actions CI/CD Workflow

```yaml
# Source: https://github.com/marketplace/actions/vitest-coverage-report + https://vitest.dev/guide/coverage
# .github/workflows/test.yml
name: Test

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run linting
        run: npm run lint

      - name: Run type checking
        run: npm run type-check

      - name: Run tests with coverage
        run: npm run test:coverage

      - name: Report coverage to PR
        if: github.event_name == 'pull_request'
        uses: davelosert/vitest-coverage-report-action@v2
        with:
          json-summary-path: ./coverage/coverage-summary.json
          json-final-path: ./coverage/coverage-final.json

      - name: Upload coverage to Codecov (optional)
        if: github.event_name == 'push'
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage/coverage-final.json

      - name: Check coverage thresholds
        run: npm run test:coverage -- --reporter=default

      - name: Archive coverage artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage
          path: coverage/
          retention-days: 30

# package.json scripts:
# {
#   "scripts": {
#     "test": "vitest",
#     "test:coverage": "vitest run --coverage",
#     "test:ui": "vitest --ui",
#     "test:watch": "vitest watch"
#   }
# }
```

### Supertest for HTTP Endpoint Testing

```typescript
// Source: https://github.com/ladjs/supertest + testing best practices
// test/integration/routes.test.ts
import { describe, it, expect, beforeAll, afterAll } from 'vitest'
import request from 'supertest'
import { app } from '../../src/app' // Express/Bolt app
import { setupTestDb, cleanupTestDb } from '../helpers/db'

describe('HTTP Routes', () => {
  beforeAll(async () => {
    await setupTestDb()
  })

  afterAll(async () => {
    await cleanupTestDb()
  })

  describe('POST /slack/events', () => {
    it('should handle app_mention event', async () => {
      const event = {
        type: 'event_callback',
        event: {
          type: 'app_mention',
          user: 'U123',
          text: '<@BOT123> help',
          channel: 'C123',
          ts: '1234567890.123456'
        }
      }

      const response = await request(app)
        .post('/slack/events')
        .send(event)
        .expect('Content-Type', /json/)
        .expect(200)

      expect(response.body).toEqual({ ok: true })
    })

    it('should handle URL verification challenge', async () => {
      const challenge = {
        type: 'url_verification',
        challenge: 'test-challenge-string'
      }

      const response = await request(app)
        .post('/slack/events')
        .send(challenge)
        .expect(200)

      expect(response.text).toBe('test-challenge-string')
    })

    it('should return 400 for invalid event', async () => {
      await request(app)
        .post('/slack/events')
        .send({ invalid: 'data' })
        .expect(400)
    })
  })

  describe('GET /health', () => {
    it('should return 200 OK', async () => {
      const response = await request(app)
        .get('/health')
        .expect(200)

      expect(response.body).toMatchObject({
        status: 'ok',
        timestamp: expect.any(Number)
      })
    })
  })
})
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Jest | **Vitest** | 2024-2025 | 10-20x faster test execution, native TypeScript/ESM support, no complex babel config, better monorepo support with `projects` |
| Testcontainers for all DB tests | **PGlite** for most tests | 2025 | Milliseconds vs seconds startup time, <3MB vs ~100MB Docker image, enables parallel test execution, no Docker required locally or CI |
| Manual mocking with jest.mock() | **MSW (Mock Service Worker)** | 2023-2024 | Network-level interception works across test types, reusable handlers, better TypeScript types, matches real HTTP behavior |
| Istanbul coverage | **V8 coverage** | 2024 | Faster, more accurate (native V8), better source map support, integrated with Vitest |
| Separate test config per package | **Vitest projects config** | 2024 (Vitest 1.0+) | Single config for monorepo, shared settings, easier maintenance, standardized patterns |
| Jest workspace config | **Vitest projects** (deprecated workspace) | 2025 (Vitest 3.2) | Workspace feature deprecated in favor of projects, clearer naming, better functionality |

**Deprecated/outdated:**
- **Jest**: Still widely used but Vitest is 10-20x faster for large codebases in 2026, especially with Vite projects
- **@slack-wrench/jest-bolt-receiver**: Useful but tied to Jest; prefer MSW + supertest with Vitest for new projects
- **Vitest workspace config**: Deprecated in Vitest 3.2, replaced by `projects` configuration
- **SQLite for testing**: Subtle behavior differences from PostgreSQL (types, constraints, JSON). Use PGlite instead.
- **Bull (predecessor to BullMQ)**: bull-mock package is 12+ years old, BullMQ is current standard, use real Redis via Testcontainers

## Open Questions

Things that couldn't be fully resolved:

1. **Slack Bolt Testing Best Practices**
   - What we know: No official testing support from Slack team as of 2022 GitHub issue, community relies on mocking internal methods
   - What's unclear: Whether Slack has released official testing utilities since 2022, best practices for testing request signing in E2E tests
   - Recommendation: Use MSW to mock Slack API responses, set `SLACK_SKIP_SIGNATURE_VERIFICATION=true` for tests, monitor Slack Bolt GitHub for testing updates

2. **BullMQ Testing Strategy: Testcontainers vs In-Memory Mock**
   - What we know: Most production BullMQ testing uses real Redis (Docker/Testcontainers), no official in-memory mock exists, bull-mock is outdated (12+ years)
   - What's unclear: Whether performance overhead of Testcontainers Redis is acceptable in CI/CD, or if simpler mock would suffice
   - Recommendation: Start with Testcontainers Redis for integration tests (higher confidence), if CI is too slow explore manual job processing via `getNextJob()`, measure actual performance before optimizing

3. **Coverage Thresholds: Team vs File-Level**
   - What we know: Vitest supports global, per-file, and per-pattern thresholds. 90%+ is target for this project.
   - What's unclear: Best way to set different thresholds for critical code (services, handlers) vs utilities without excessive config
   - Recommendation: Use pattern-based thresholds `'src/services/**.ts': { lines: 90 }`, document rationale in vitest.config.ts comments, review coverage reports manually to catch gaps

4. **Testing Page (/test route) Security**
   - What we know: Need manual testing UI accessible at `/test` for debugging handlers
   - What's unclear: How to secure this route in production (accidental deploy), whether to use separate Express app or environment checks
   - Recommendation: Gate route behind `NODE_ENV !== 'production'` check, or use environment variable `ENABLE_TEST_ROUTE=true`, add warning banner on page

## Sources

### Primary (HIGH confidence)
- [Vitest Official Guide](https://vitest.dev/guide/) - Core framework documentation, configuration, features
- [Vitest Config Reference](https://vitest.dev/config/) - Coverage thresholds, projects, environment settings
- [MSW Getting Started](https://mswjs.io/docs/getting-started) - HTTP mocking setup, Node.js integration
- [Testcontainers for Node.js](https://testcontainers.com/guides/getting-started-with-testcontainers-for-nodejs/) - PostgreSQL integration testing
- [PGlite Official Site](https://pglite.dev/) - WASM PostgreSQL features and benefits
- [Drizzle ORM - PGlite Connection](https://orm.drizzle.team/docs/connect-pglite) - Official Drizzle + PGlite setup

### Secondary (MEDIUM confidence)
- [Better Stack: Node.js Testing Libraries Comparison](https://betterstack.com/community/guides/testing/best-node-testing-libraries/) - Framework comparison with benchmarks
- [GitHub: nodejs-testing-best-practices](https://github.com/goldbergyoni/nodejs-testing-best-practices) - Comprehensive best practices (April 2025)
- [DEV Community: Testing Node.js & Postgres with Drizzle & PGlite](https://dev.to/benjamindaniel/how-to-test-your-nodejs-postgres-app-using-drizzle-pglite-4fb3) - PGlite setup guide
- [GitHub: rphlmr/drizzle-vitest-pg](https://github.com/rphlmr/drizzle-vitest-pg) - Working example of Drizzle + Vitest + PGlite
- [Medium: Testing BullMQ Jobs with Jest](https://medium.com/@vijaysinh.khot/testing-the-untestable-a-guide-to-integration-testing-bullmq-jobs-with-jest-736db303ca2e) - Job queue testing patterns
- [GitHub Marketplace: Vitest Coverage Report Action](https://github.com/marketplace/actions/vitest-coverage-report) - CI/CD coverage reporting
- [GitHub Issue: Slack Bolt Testing Support (#1336)](https://github.com/slackapi/bolt-js/issues/1336) - Community discussion on Bolt testing
- [Express Debug Tool](https://github.com/devoidfury/express-debug) - Debug dashboard middleware for Express

### Tertiary (LOW confidence)
- [WebSearch: TypeScript testing frameworks 2026](https://betterstack.com/community/guides/testing/best-node-testing-libraries/) - General framework trends
- [WebSearch: Vitest vs Jest 2026](https://dev.to/dataformathub/vitest-vs-jest-30-why-2026-is-the-year-of-browser-native-testing-2fgb) - Performance comparisons
- [LinkedIn: Unit Testing Pitfalls](https://www.linkedin.com/advice/0/what-some-common-unit-testing-pitfalls-anti-patterns) - Anti-patterns to avoid
- [Codepipes: Software Testing Anti-patterns](https://blog.codepipes.com/testing/software-testing-antipatterns.html) - Testing anti-patterns

## Metadata

**Confidence breakdown:**
- Standard stack: **HIGH** - Vitest, MSW, PGlite verified via official docs and active community usage in 2026
- Architecture: **HIGH** - Patterns verified via official documentation and working examples from maintained repos
- Pitfalls: **MEDIUM** - Based on community discussions and real GitHub issues, but not all issues are dated recently
- Slack Bolt testing: **MEDIUM** - No official support confirmed via GitHub issues, community patterns are unverified by Slack
- BullMQ testing: **MEDIUM** - Multiple approaches exist but no clear official recommendation, Testcontainers appears most reliable

**Research date:** 2026-01-26
**Valid until:** 2026-04-26 (90 days - testing tools are relatively stable, but Vitest releases frequently)

**Key assumptions:**
- TypeScript 5.7+ and Node.js 20+ (per package.json)
- npm workspaces monorepo structure (confirmed)
- Turbo for build orchestration (per package.json)
- PostgreSQL as production database (per requirements)
- BullMQ for job queue (per requirements)

**Areas requiring validation during planning:**
- Exact Vitest version compatibility with current Turbo setup
- Whether CI/CD already has Docker (affects Testcontainers vs PGlite decision for BullMQ)
- Current test coverage (if any) to understand baseline
- Whether `/test` route security requirements differ from recommendation
