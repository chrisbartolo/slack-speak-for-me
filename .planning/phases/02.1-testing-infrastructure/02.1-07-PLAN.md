---
phase: 02.1-testing-infrastructure
plan: 07
type: execute
wave: 3
depends_on: ["02.1-02", "02.1-03", "02.1-04"]
files_modified:
  - apps/slack-backend/test/integration/database.test.ts
  - apps/slack-backend/test/integration/job-queue.test.ts
autonomous: true

must_haves:
  truths:
    - "Database integration tests use real PostgreSQL via PGlite"
    - "Job queue tests verify worker processes jobs correctly"
    - "Integration tests run independently without mocking business logic"
  artifacts:
    - path: "apps/slack-backend/test/integration/database.test.ts"
      provides: "Integration tests for database operations"
      min_lines: 80
    - path: "apps/slack-backend/test/integration/job-queue.test.ts"
      provides: "Integration tests for BullMQ workers"
      min_lines: 100
  key_links:
    - from: "apps/slack-backend/test/integration/job-queue.test.ts"
      to: "jobs/workers.ts"
      via: "Worker import"
      pattern: "Worker|startWorkers"
---

<objective>
Create integration tests for database operations and job queue processing.

Purpose: Verify components work together correctly with real database and message queue
Output: Integration tests that exercise real database and job processing
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02.1-testing-infrastructure/02.1-RESEARCH.md
@apps/slack-backend/src/jobs/workers.ts
@apps/slack-backend/src/jobs/queues.ts
@apps/slack-backend/test/helpers/db.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database integration tests</name>
  <files>apps/slack-backend/test/integration/database.test.ts</files>
  <action>
Create integration tests that verify database operations work correctly together.

These tests use PGlite (real PostgreSQL) instead of mocks.

**Test workspace and installation lifecycle:**
1. `should create workspace and installation together`
   - Insert workspace
   - Insert installation referencing workspace
   - Verify both records exist

2. `should enforce workspace.team_id uniqueness`
   - Insert workspace with team_id
   - Attempt duplicate
   - Verify constraint error

3. `should cascade correctly (foreign key behavior)`
   - Verify installation.workspace_id references valid workspace

**Test watched conversations:**
1. `should insert watched conversation`
   - Insert workspace first
   - Insert watched conversation
   - Query and verify

2. `should enforce unique constraint on (workspace_id, user_id, channel_id)`
   - Insert watch
   - Attempt duplicate
   - Verify conflict handling

3. `should allow multiple watches per user (different channels)`
   - Same user watches C123 and C456
   - Both records exist

4. `should allow multiple users to watch same channel`
   - User1 and User2 both watch C123
   - Both records exist

5. `should delete watch correctly`
   - Create and delete
   - Verify record gone

**Test thread participants:**
1. `should insert thread participation`

2. `should update lastMessageAt on conflict`
   - Insert participation
   - Insert again (upsert)
   - Verify timestamp updated

3. `should query by thread correctly`
   - Multiple participants in same thread
   - Query returns all

4. `should filter by time window (7 days)`
   - Insert old participation (manually set timestamp)
   - Query with date filter
   - Verify old records excluded

**Test complex queries:**
1. `should join installations with workspaces`
   - Create workspace and installation
   - Query with join
   - Verify both tables data returned

Structure:
```typescript
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { eq, and } from 'drizzle-orm';
import { setupTestDb, cleanupTestDb } from '../helpers/db';
import * as schema from '@slack-speak/database';

describe('Database Integration', () => {
  let db: Awaited<ReturnType<typeof setupTestDb>>;

  beforeEach(async () => {
    db = await setupTestDb();
  });

  afterEach(async () => {
    await cleanupTestDb();
  });

  describe('Workspaces', () => {
    it('should insert and query workspace', async () => {
      await db.insert(schema.workspaces).values({
        teamId: 'T123',
        name: 'Test Workspace',
      });

      const results = await db.select()
        .from(schema.workspaces)
        .where(eq(schema.workspaces.teamId, 'T123'));

      expect(results).toHaveLength(1);
      expect(results[0].name).toBe('Test Workspace');
    });
    // ... more tests
  });

  describe('Watched Conversations', () => {
    // ... tests
  });

  describe('Thread Participants', () => {
    // ... tests
  });
});
```
  </action>
  <verify>
`npm run test -- test/integration/database.test.ts --run` passes
All database operations work correctly with PGlite
  </verify>
  <done>
Database integration tests verify CRUD operations and constraints with real PostgreSQL
  </done>
</task>

<task type="auto">
  <name>Task 2: Job queue integration tests</name>
  <files>apps/slack-backend/test/integration/job-queue.test.ts</files>
  <action>
Create integration tests for BullMQ job processing.

**In-memory testing approach (no real Redis required):**

For unit/integration tests, directly call the worker processor function with mock job data. This tests the actual processing logic without needing Redis infrastructure.

```typescript
import { describe, it, expect, beforeAll, afterAll, vi } from 'vitest';
import { setupTestDb, cleanupTestDb, getTestDb } from '../helpers/db';
import { server } from '../setup';
import { http, HttpResponse } from 'msw';

// Import the processor function directly (may need to export it from workers.ts)
// If not exported, import the worker module and access the processor
import { processAIResponseJob } from '../../src/jobs/workers';

describe('Job Queue Integration', () => {
  let testDb: Awaited<ReturnType<typeof setupTestDb>>;

  beforeAll(async () => {
    testDb = await setupTestDb();
  });

  afterAll(async () => {
    await cleanupTestDb();
  });

  // Helper to create mock job object matching BullMQ Job interface
  function createMockJob(data: any, opts: Partial<{ id: string; attemptsMade: number }> = {}) {
    return {
      id: opts.id || 'job_test_123',
      data,
      attemptsMade: opts.attemptsMade || 0,
      updateProgress: vi.fn(),
      log: vi.fn(),
    };
  }

  describe('AI Response Job Processing', () => {
    it('should process job and generate suggestion', async () => {
      const job = createMockJob({
        workspaceId: 'W123',
        userId: 'U123',
        channelId: 'C123',
        messageTs: '1234567890.000001',
        triggerMessageText: 'Help me respond to this',
        contextMessages: [{ userId: 'U456', text: 'Previous message', ts: '1234567890.000000' }],
        triggeredBy: 'mention',
      });

      const result = await processAIResponseJob(job as any);

      expect(result).toHaveProperty('suggestion');
      expect(result).toHaveProperty('processingTimeMs');
      expect(result).toHaveProperty('suggestionId');
    });

    it('should handle missing installation gracefully', async () => {
      const job = createMockJob({
        workspaceId: 'NONEXISTENT',
        userId: 'U123',
        channelId: 'C123',
        messageTs: '1234567890.000001',
        triggerMessageText: 'Test',
        contextMessages: [],
        triggeredBy: 'mention',
      });

      // Should complete generation but log error for delivery
      const result = await processAIResponseJob(job as any);
      expect(result.suggestion).toBeTruthy();
    });

    it('should handle AI API errors', async () => {
      server.use(
        http.post('https://api.anthropic.com/v1/messages', () => {
          return HttpResponse.json({ error: 'Rate limited' }, { status: 429 });
        })
      );

      const job = createMockJob({
        workspaceId: 'W123',
        userId: 'U123',
        channelId: 'C123',
        messageTs: '1234567890.000001',
        triggerMessageText: 'Test',
        contextMessages: [],
        triggeredBy: 'mention',
      });

      await expect(processAIResponseJob(job as any)).rejects.toThrow();
    });

    it('should deliver suggestion via chat.postEphemeral', async () => {
      let ephemeralCalled = false;
      let ephemeralPayload: any = null;

      server.use(
        http.post('https://slack.com/api/chat.postEphemeral', async ({ request }) => {
          ephemeralCalled = true;
          ephemeralPayload = await request.json();
          return HttpResponse.json({ ok: true });
        })
      );

      // Seed installation for delivery
      await testDb.insert(schema.installations).values({
        workspaceId: 'W123',
        botToken: 'xoxb-test-token',
        // ... other required fields
      });

      const job = createMockJob({
        workspaceId: 'W123',
        userId: 'U123',
        channelId: 'C123',
        messageTs: '1234567890.000001',
        triggerMessageText: 'Test',
        contextMessages: [],
        triggeredBy: 'mention',
      });

      await processAIResponseJob(job as any);

      expect(ephemeralCalled).toBe(true);
      expect(ephemeralPayload.channel).toBe('C123');
      expect(ephemeralPayload.user).toBe('U123');
    });

    it('should emit result with suggestionId and processingTimeMs', async () => {
      const job = createMockJob({
        workspaceId: 'W123',
        userId: 'U123',
        channelId: 'C123',
        messageTs: '1234567890.000001',
        triggerMessageText: 'Test',
        contextMessages: [],
        triggeredBy: 'mention',
      });

      const result = await processAIResponseJob(job as any);

      expect(result.suggestionId).toMatch(/^sug_/);
      expect(typeof result.processingTimeMs).toBe('number');
      expect(result.processingTimeMs).toBeGreaterThan(0);
    });
  });
});
```

**Note on BullMQ integration tests (E2E scope):**
Full BullMQ integration tests with real Redis (via Testcontainers) are E2E scope - they verify queue mechanics (add job, worker picks up, events fire) rather than processing logic. The above tests verify the processor itself works correctly.

If E2E tests with real Redis are needed later, use Testcontainers:
```typescript
// E2E only - requires Docker
import { GenericContainer } from 'testcontainers';
const redisContainer = await new GenericContainer('redis:7-alpine').withExposedPorts(6379).start();
```
  </action>
  <verify>
`npm run test -- test/integration/job-queue.test.ts --run` passes
Job processing logic verified without requiring Redis
  </verify>
  <done>
Job queue integration tests verify worker processor logic correctly
  </done>
</task>

</tasks>

<verification>
Run integration tests:
1. `npm run test -- test/integration/*.test.ts --run`
2. Verify database tests use PGlite successfully
3. Verify job tests call processor directly without Redis dependency
</verification>

<success_criteria>
- database.test.ts has 12+ tests covering all tables
- job-queue.test.ts has 5+ tests covering job processing logic
- Tests use real PostgreSQL (PGlite) not mocks
- Job tests call processor directly (in-memory, no Redis required)
- All CRUD operations verified
- Foreign key constraints verified
- Job processing verified via direct processor call
</success_criteria>

<output>
After completion, create `.planning/phases/02.1-testing-infrastructure/02.1-07-SUMMARY.md`
</output>
