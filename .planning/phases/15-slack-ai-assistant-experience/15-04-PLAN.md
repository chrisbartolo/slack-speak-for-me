---
phase: 15-slack-ai-assistant-experience
plan: 04
type: execute
wave: 3
depends_on: ["15-03"]
files_modified:
  - apps/slack-backend/src/assistant/streaming.ts
  - apps/slack-backend/src/assistant/feedback.ts
  - apps/slack-backend/src/assistant/handlers/user-message.ts
  - apps/slack-backend/src/services/ai.ts
autonomous: true

must_haves:
  truths:
    - "User types in assistant panel and receives a streaming AI response that appears progressively"
    - "AI response is contextually aware of the channel the user is viewing"
    - "Response completes with feedback buttons (thumbs up/down)"
    - "Assistant shows thinking status during generation and clears it after"
  artifacts:
    - path: "apps/slack-backend/src/assistant/streaming.ts"
      provides: "Streaming pipeline connecting Anthropic SDK to Slack chatStream"
      exports: ["streamSuggestionToAssistant"]
    - path: "apps/slack-backend/src/assistant/feedback.ts"
      provides: "Feedback block builder for context_actions with feedback_buttons"
      exports: ["createFeedbackBlock"]
    - path: "apps/slack-backend/src/services/ai.ts"
      provides: "Streaming variant of AI generation"
      exports: ["generateSuggestionStream"]
  key_links:
    - from: "apps/slack-backend/src/assistant/handlers/user-message.ts"
      to: "apps/slack-backend/src/assistant/streaming.ts"
      via: "import and call streamSuggestionToAssistant"
      pattern: "streamSuggestionToAssistant"
    - from: "apps/slack-backend/src/assistant/streaming.ts"
      to: "apps/slack-backend/src/services/ai.ts"
      via: "import and call generateSuggestionStream"
      pattern: "generateSuggestionStream"
    - from: "apps/slack-backend/src/assistant/streaming.ts"
      to: "@slack/web-api chatStream"
      via: "client.chatStream()"
      pattern: "client\\.chatStream"
---

<objective>
Wire the AI generation service into Slack's chatStream() streaming pipeline so users see progressive response generation in the assistant panel, with feedback buttons on completion.

Purpose: Streaming responses provide real-time feedback to users and feel more responsive than waiting for a complete response. The feedback buttons enable quality tracking.
Output: Users see AI suggestions streaming in the assistant panel with feedback buttons at the end.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/15-slack-ai-assistant-experience/15-RESEARCH.md
@apps/slack-backend/src/services/ai.ts
@apps/slack-backend/src/assistant/handlers/user-message.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create streaming AI generation and feedback block</name>
  <files>
    apps/slack-backend/src/services/ai.ts
    apps/slack-backend/src/assistant/feedback.ts
  </files>
  <action>
1. Add a `generateSuggestionStream` function to `apps/slack-backend/src/services/ai.ts`:
   - This function should be similar to `generateSuggestion` but return an Anthropic streaming response instead of waiting for completion.
   - Signature:
     ```typescript
     export async function generateSuggestionStream(
       context: SuggestionContext
     ): Promise<{
       stream: AsyncIterable<any>;  // Anthropic MessageStream
       usageCheck: { currentUsage: number; limit: number; isOverage: boolean };
     }>
     ```
   - It should:
     a. Call `checkUsageAllowed()` — same as `generateSuggestion`. Throw `UsageLimitExceededError` if not allowed.
     b. Build style context via `buildStyleContext()` — same as `generateSuggestion`
     c. Fetch conversation context, person contexts, client context, org style, templates — reuse the same logic from `generateSuggestion`. To avoid massive duplication, extract the prompt-building logic into a shared private helper function called `buildSuggestionPrompt(context: SuggestionContext)` that returns `{ systemPrompt: Array<{type: string, text: string, cache_control: any}>, userPrompt: string, metadata: { organizationId?: string, styleContext: any, sentimentResult: any, kbResults: any[], clientContext: string, orgStyleContext: string, templateContext: string } }`. Both `generateSuggestion` and `generateSuggestionStream` should use this shared helper.
     d. Call `anthropic.messages.create({ ...sameParams, stream: true })` to get a streaming response
     e. Return the stream and usage check info (the caller handles recording usage after streaming completes)
   - Do NOT break the existing `generateSuggestion` function. Refactor it to use the shared helper but keep its exact same return type and behavior.

2. Create `apps/slack-backend/src/assistant/feedback.ts`:
   - Export `createFeedbackBlock(suggestionId: string)` that returns a block object:
     ```typescript
     export function createFeedbackBlock(suggestionId: string) {
       return {
         type: 'context_actions' as const,
         elements: [
           {
             type: 'feedback_buttons' as const,
             action_id: 'ai_feedback',
             positive_button: {
               text: { type: 'plain_text' as const, text: 'Good' },
               value: JSON.stringify({ suggestionId, feedback: 'positive' }),
               accessibility_label: 'This was a good suggestion',
             },
             negative_button: {
               text: { type: 'plain_text' as const, text: 'Bad' },
               value: JSON.stringify({ suggestionId, feedback: 'negative' }),
               accessibility_label: 'This was a bad suggestion',
             },
           },
         ],
       };
     }
     ```
   - Note: The `context_actions` block type and `feedback_buttons` element type may not exist in Bolt v4's TypeScript types yet. If so, use `as any` for the block type. The API supports it even if types are behind.
  </action>
  <verify>
`npm run build --workspace=@slack-speak/slack-backend` compiles without errors. Both `generateSuggestion` (existing) and `generateSuggestionStream` (new) are exported from ai.ts.
  </verify>
  <done>
Streaming AI generation function created. Feedback block builder created. Existing generateSuggestion function unchanged in behavior.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create streaming pipeline and wire into userMessage handler</name>
  <files>
    apps/slack-backend/src/assistant/streaming.ts
    apps/slack-backend/src/assistant/handlers/user-message.ts
  </files>
  <action>
1. Create `apps/slack-backend/src/assistant/streaming.ts`:
   - Export `streamSuggestionToAssistant(options)` function:
     ```typescript
     interface StreamOptions {
       client: WebClient;
       channelId: string;        // Assistant thread channel
       threadTs: string;         // Assistant thread timestamp
       userText: string;         // User's message/request
       viewingChannelId?: string;  // Channel user is viewing (from ThreadContextStore)
       viewingThreadTs?: string;   // Thread timestamp user is viewing (if viewing a specific thread)
       workspaceId: string;
       userId: string;
     }

     export async function streamSuggestionToAssistant(options: StreamOptions): Promise<void>
     ```
   - Implementation:
     a. Fetch context messages from the `viewingChannelId` (if available) using `getContextForMessage` from existing context service. If no viewingChannelId, skip context fetch.
     b. Call `generateSuggestionStream()` with the context, treating `userText` as the trigger message
     c. Create a `chatStream` instance: `const streamer = client.chatStream({ channel: channelId, thread_ts: threadTs })`
     d. Iterate over the Anthropic stream:
        ```typescript
        for await (const event of stream) {
          if (event.type === 'content_block_delta' && event.delta.type === 'text_delta') {
            await streamer.append({ markdown_text: event.delta.text });
          }
        }
        ```
     e. Generate a suggestion ID: `const suggestionId = 'sug_' + Date.now() + '_' + Math.random().toString(36).slice(2, 9)`
     f. Stop the stream with feedback block: `await streamer.stop({ blocks: [createFeedbackBlock(suggestionId)] })`
     g. Record usage event (fire-and-forget, same pattern as workers.ts)
     h. Log success with processingTimeMs, suggestionId, channelId

   - Import `{ WebClient } from '@slack/web-api'`
   - Import `{ generateSuggestionStream } from '../services/ai.js'`
   - Import `{ createFeedbackBlock } from './feedback.js'`
   - Import `{ getContextForMessage } from '../services/context.js'`
   - Import `{ getWorkspaceId } from '../services/watch.js'`
   - Import `{ recordUsageEvent } from '../services/usage-enforcement.js'`
   - Import `{ logger } from '../utils/logger.js'`

2. Update `apps/slack-backend/src/assistant/handlers/user-message.ts`:
   - Replace the placeholder response with the actual streaming pipeline
   - Implementation:
     ```typescript
     export async function handleUserMessage({ say, client, setTitle, setStatus, event, context }: any) {
       const userText = event.text || '';
       const channelId = event.channel;
       const threadTs = event.thread_ts;

       try {
         await setTitle(userText.slice(0, 50) || 'Response suggestion');
         await setStatus('thinking...');

         // Get viewing channel and thread from thread context (set by threadContextChanged)
         const viewingChannelId = context?.channel_id;
         const viewingThreadTs = context?.thread_ts;

         // Get workspace ID from auth
         const authResult = await client.auth.test();
         const teamId = authResult.team_id;
         const workspaceId = await getWorkspaceId(teamId);

         if (!workspaceId) {
           await setStatus('');
           await say({ text: 'Sorry, I could not find your workspace. Please reinstall the app.' });
           return;
         }

         await setStatus('generating response...');

         await streamSuggestionToAssistant({
           client,
           channelId,
           threadTs,
           userText,
           viewingChannelId,
           viewingThreadTs,
           workspaceId,
           userId: event.user,
         });

         await setStatus('');
       } catch (error: any) {
         logger.error({ error }, 'Error in assistant userMessage handler');
         await setStatus('');

         if (error.name === 'UsageLimitExceededError') {
           await say({
             text: `You've reached your usage limit (${error.currentUsage}/${error.limit} suggestions). Upgrade your plan for more.`,
           });
         } else {
           await say({
             text: 'Sorry, I encountered an error generating that response. Please try again.',
           });
         }
       }
     }
     ```
   - Import `{ streamSuggestionToAssistant } from '../streaming.js'`
   - Import `{ getWorkspaceId } from '../../services/watch.js'`
   - Import `{ logger } from '../../utils/logger.js'`
  </action>
  <verify>
`npm run build --workspace=@slack-speak/slack-backend` compiles without errors. `grep 'chatStream' apps/slack-backend/src/assistant/streaming.ts` returns a match. `grep 'viewingThreadTs' apps/slack-backend/src/assistant/streaming.ts` confirms the field is in StreamOptions.
  </verify>
  <done>
Streaming pipeline connects Anthropic SDK streaming to Slack's chatStream() utility. The userMessage handler calls streamSuggestionToAssistant which fetches context, generates a streaming AI response, pipes chunks to the assistant panel, and finishes with feedback buttons. Usage limits are enforced. Errors are handled gracefully. StreamOptions includes viewingThreadTs for thread-level context passed to action buttons.
  </done>
</task>

</tasks>

<verification>
1. `npm run build --workspace=@slack-speak/slack-backend` — zero errors
2. `grep 'generateSuggestionStream' apps/slack-backend/src/services/ai.ts` — new function exists
3. `grep 'chatStream' apps/slack-backend/src/assistant/streaming.ts` — streaming wired
4. `grep 'createFeedbackBlock' apps/slack-backend/src/assistant/feedback.ts` — feedback block exists
5. `grep 'streamSuggestionToAssistant' apps/slack-backend/src/assistant/handlers/user-message.ts` — wired into handler
6. `grep 'viewingThreadTs' apps/slack-backend/src/assistant/streaming.ts` — thread ts available for action buttons
</verification>

<success_criteria>
- User types in assistant panel and receives streaming AI response
- Response includes conversation context from the channel user is viewing
- Feedback buttons (thumbs up/down) appear after response completes
- Usage limits enforced before generation
- Errors handled gracefully with user-friendly messages
- Existing generateSuggestion function unchanged in behavior
- StreamOptions includes viewingThreadTs for downstream action button wiring
</success_criteria>

<output>
After completion, create `.planning/phases/15-slack-ai-assistant-experience/15-04-SUMMARY.md`
</output>
