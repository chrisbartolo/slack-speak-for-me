---
phase: 02-core-slack-response-suggestions
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/slack-backend/src/services/ai.ts
  - apps/slack-backend/src/services/index.ts
  - apps/slack-backend/src/jobs/workers.ts
  - apps/slack-backend/package.json
autonomous: true

user_setup:
  - service: anthropic
    why: "AI suggestion generation"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys -> Create Key"
    dashboard_config: []

must_haves:
  truths:
    - "AI can generate contextually-aware response suggestions"
    - "Job worker processes AI response jobs and generates suggestions"
    - "Suggestions are generated using conversation context"
  artifacts:
    - path: "apps/slack-backend/src/services/ai.ts"
      provides: "AI suggestion generation"
      exports: ["generateSuggestion"]
    - path: "apps/slack-backend/src/jobs/workers.ts"
      provides: "BullMQ worker that calls AI service"
      contains: "generateSuggestion"
  key_links:
    - from: "apps/slack-backend/src/jobs/workers.ts"
      to: "apps/slack-backend/src/services/ai.ts"
      via: "import and call"
      pattern: "generateSuggestion"
    - from: "apps/slack-backend/src/services/ai.ts"
      to: "@anthropic-ai/sdk"
      via: "SDK client"
      pattern: "Anthropic|messages\\.create"
---

<objective>
Integrate Claude AI for generating response suggestions and wire the BullMQ worker to process AI jobs.

Purpose: Enable the core AI capability - generating contextually-aware response suggestions that will be delivered to users via ephemeral messages.

Output: AI service that calls Claude API, updated BullMQ worker that processes suggestion jobs.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-slack-response-suggestions/02-RESEARCH.md

@apps/slack-backend/src/jobs/types.ts
@apps/slack-backend/src/jobs/workers.ts
@apps/slack-backend/src/jobs/queues.ts
@packages/validation/src/sanitization.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Anthropic SDK and create AI suggestion service</name>
  <files>
    apps/slack-backend/package.json
    apps/slack-backend/src/services/ai.ts
    apps/slack-backend/src/env.ts
  </files>
  <action>
1. Install Anthropic SDK:
```bash
npm install @anthropic-ai/sdk --workspace=apps/slack-backend
```

2. Update apps/slack-backend/src/env.ts to validate ANTHROPIC_API_KEY:
   - Add ANTHROPIC_API_KEY to the Zod schema (required string)
   - Add helpful error message if missing

3. Create apps/slack-backend/src/services/ai.ts:

```typescript
import Anthropic from '@anthropic-ai/sdk';
import { env } from '../env.js';
import { prepareForAI, sanitizeAIOutput } from '@slack-speak/validation';
import { logger } from '../utils/logger.js';

const anthropic = new Anthropic({
  apiKey: env.ANTHROPIC_API_KEY,
});

interface SuggestionContext {
  triggerMessage: string;
  contextMessages: Array<{
    userId: string;
    text: string;
    ts: string;
  }>;
  triggeredBy: 'mention' | 'reply' | 'thread' | 'message_action';
}

interface SuggestionResult {
  suggestion: string;
  processingTimeMs: number;
}

export async function generateSuggestion(
  context: SuggestionContext
): Promise<SuggestionResult> {
  const startTime = Date.now();

  // Format context messages for the prompt
  const formattedContext = context.contextMessages
    .map(m => `[${m.ts}] User ${m.userId}: ${m.text}`)
    .join('\n');

  // Prepare user content with sanitization and spotlighting
  const sanitizedTrigger = prepareForAI(context.triggerMessage);
  const sanitizedContext = prepareForAI(formattedContext);

  const systemPrompt = `You are a helpful assistant that suggests professional, thoughtful responses to workplace messages. Your suggestions should:
- Be appropriate for professional communication
- Match a neutral, professional tone
- Be concise but complete
- Address the key points in the message
- Not be aggressive or confrontational

When suggesting responses, consider the conversation context provided. Generate a single suggested response that the user can copy and send.`;

  const userPrompt = `Here is the recent conversation context:
${sanitizedContext}

The user needs help responding to this message:
${sanitizedTrigger}

Trigger type: ${context.triggeredBy}

Please suggest a professional response the user could send. Provide only the suggested response text, no additional commentary.`;

  try {
    const response = await anthropic.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 1024,
      system: systemPrompt,
      messages: [
        {
          role: 'user',
          content: userPrompt,
        },
      ],
    });

    const rawSuggestion = response.content[0].type === 'text'
      ? response.content[0].text
      : '';

    // Sanitize AI output before returning
    const suggestion = sanitizeAIOutput(rawSuggestion);

    const processingTimeMs = Date.now() - startTime;

    logger.info({
      processingTimeMs,
      inputTokens: response.usage.input_tokens,
      outputTokens: response.usage.output_tokens,
    }, 'AI suggestion generated');

    return {
      suggestion,
      processingTimeMs,
    };
  } catch (error) {
    logger.error({ error }, 'Failed to generate AI suggestion');
    throw error;
  }
}
```

Implementation notes:
- Use prepareForAI from validation package (sanitizes + spotlights)
- Use sanitizeAIOutput to filter any leaked system content
- Log token usage for cost monitoring
- Handle errors with logger, rethrow for worker retry logic
  </action>
  <verify>
Run `npm run build --workspaces --if-present` - TypeScript compiles without errors.
Verify AI service export: `grep "export.*generateSuggestion" apps/slack-backend/src/services/ai.ts`
  </verify>
  <done>
Anthropic SDK installed.
ai.ts exports generateSuggestion function.
env.ts validates ANTHROPIC_API_KEY.
TypeScript compiles without errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update BullMQ worker to call AI service and return results</name>
  <files>
    apps/slack-backend/src/jobs/workers.ts
    apps/slack-backend/src/services/index.ts
  </files>
  <action>
1. Update apps/slack-backend/src/services/index.ts to export AI service:
```typescript
export { generateSuggestion } from './ai.js';
// ... other exports
```

2. Update apps/slack-backend/src/jobs/workers.ts to implement actual AI processing:

Replace the placeholder job processor with real AI generation:

```typescript
import { Worker } from 'bullmq';
import { redis } from './connection.js';
import { logger } from '../utils/logger.js';
import { generateSuggestion } from '../services/index.js';
import type { AIResponseJobData, AIResponseJobResult } from './types.js';

export const aiResponseWorker = new Worker<AIResponseJobData, AIResponseJobResult>(
  'ai-responses',
  async (job) => {
    const { workspaceId, userId, channelId, messageTs, triggerMessageText, contextMessages, triggeredBy } = job.data;

    logger.info({
      jobId: job.id,
      workspaceId,
      userId,
      triggeredBy,
    }, 'Processing AI response job');

    const result = await generateSuggestion({
      triggerMessage: triggerMessageText,
      contextMessages,
      triggeredBy,
    });

    // Generate a unique suggestion ID for tracking
    const suggestionId = `sug_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`;

    logger.info({
      jobId: job.id,
      suggestionId,
      processingTimeMs: result.processingTimeMs,
    }, 'AI suggestion generated successfully');

    return {
      suggestionId,
      suggestion: result.suggestion,
      processingTimeMs: result.processingTimeMs,
    };
  },
  {
    connection: redis,
    concurrency: 5,
    limiter: {
      max: 10,
      duration: 1000, // 10 jobs per second
    },
  }
);

// Keep existing event handlers for error, failed, completed, stalled
aiResponseWorker.on('error', (err) => {
  logger.error({ error: err }, 'Worker error');
});

aiResponseWorker.on('failed', (job, err) => {
  logger.error({
    jobId: job?.id,
    error: err.message,
    attempts: job?.attemptsMade,
  }, 'Job failed');
});

aiResponseWorker.on('completed', (job, result) => {
  logger.info({
    jobId: job.id,
    suggestionId: result.suggestionId,
    processingTimeMs: result.processingTimeMs,
  }, 'Job completed');
});

aiResponseWorker.on('stalled', (jobId) => {
  logger.warn({ jobId }, 'Job stalled');
});
```

Implementation notes:
- Import generateSuggestion from services
- Generate unique suggestionId for tracking ephemeral messages
- Keep existing rate limiting config (10 jobs/second, concurrency 5)
- Keep existing event handlers but enhance logging
- The worker returns AIResponseJobResult that Plan 06 will use to send ephemeral messages
  </action>
  <verify>
Run `npm run build --workspaces --if-present` - TypeScript compiles without errors.
Verify worker imports AI service: `grep "generateSuggestion" apps/slack-backend/src/jobs/workers.ts`
  </verify>
  <done>
Worker calls generateSuggestion from AI service.
Job processor returns AIResponseJobResult with suggestionId, suggestion, and processingTimeMs.
TypeScript compiles without errors.
  </done>
</task>

</tasks>

<verification>
1. Run `npm run build --workspaces --if-present` - all packages compile
2. Verify Anthropic SDK installed: `grep "@anthropic-ai/sdk" apps/slack-backend/package.json`
3. Verify AI service: `grep "export.*generateSuggestion" apps/slack-backend/src/services/ai.ts`
4. Verify worker integration: `grep "generateSuggestion" apps/slack-backend/src/jobs/workers.ts`
5. Verify env validation: `grep "ANTHROPIC_API_KEY" apps/slack-backend/src/env.ts`
</verification>

<success_criteria>
- Anthropic SDK installed and configured
- AI service generates suggestions using Claude claude-sonnet-4-20250514
- Input sanitization and output filtering applied
- Worker calls AI service and returns structured results
- All code compiles without TypeScript errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-slack-response-suggestions/02-02-SUMMARY.md`
</output>
